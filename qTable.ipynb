{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Learning with Q-Tables and OpenAI Gym\n",
    "\n",
    "## Taxi-Environment\n",
    "![screenshot of environment](Screenshot_Taxi.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries\n",
    "import numpy as np\n",
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action Space: Discrete(6)\n",
      "State Space: Discrete(500)\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "discount_factor = 0.01\n",
    "gamma =0.5\n",
    "alpha = 0.5     #learning_rate\n",
    "epochs = 1001\n",
    "epsilon =0.3    #exploration_rate\n",
    "state= 328\n",
    "\n",
    "# Start of playground\n",
    "env = gym.make(\"Taxi-v3\").env\n",
    "env.reset()\n",
    "\n",
    "print(f\"Action Space: {env.action_space}\")\n",
    "print(f\"State Space: {env.observation_space}\")\n",
    "\n",
    "qTable = np.zeros([env.observation_space.n,env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :G|\n",
      "| : | :\u001b[43m \u001b[0m: |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Episode: 100\n",
      "Episode: 200\n",
      "Episode: 300\n",
      "Episode: 400\n",
      "Episode: 500\n",
      "Episode: 600\n",
      "Episode: 700\n",
      "Episode: 800\n",
      "Episode: 900\n"
     ]
    }
   ],
   "source": [
    "# Learning\n",
    "frames = []        # saves renderings for video of learning process\n",
    "for i in range(epochs):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "\n",
    "    penalties, reward = 0, 0\n",
    "    while not done:\n",
    "        if random.uniform(0,1) <epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(qTable[state])\n",
    "            \n",
    "        next_state, reward, done, _ = env.step(action) \n",
    "        old_q = qTable[state,action]\n",
    "        next_max = np.max(qTable[next_state])\n",
    "        new_q = (1-alpha)*old_q + alpha*(reward+gamma*next_max)\n",
    "        qTable[state,action]=new_q\n",
    "        \n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "\n",
    "        state = next_state\n",
    "        \n",
    "        frames.append({\n",
    "            'frame': env.render(mode='ansi'),\n",
    "            'state': state,\n",
    "            'action': action,\n",
    "            'reward': reward\n",
    "            }      \n",
    "        )\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Episode: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : :\u001b[42m_\u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |B: |\n",
      "+---------+\n",
      "  (South)\n",
      "\n",
      "Timestep: 50\n",
      "State: 256\n",
      "Action: 0\n",
      "Reward: -1\n"
     ]
    }
   ],
   "source": [
    "# Plotting function\n",
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "def print_frames(frames):\n",
    "    for i, frame in enumerate(frames):\n",
    "        clear_output(wait=True)\n",
    "        print(frame['frame'])#.getvalue())\n",
    "        print(f\"Timestep: {i + 1}\")\n",
    "        print(f\"State: {frame['state']}\")\n",
    "        print(f\"Action: {frame['action']}\")\n",
    "        print(f\"Reward: {frame['reward']}\")\n",
    "        sleep(.1)\n",
    "        \n",
    "# shows video of learning process \n",
    "print_frames(frames[950:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 1000 episodes:\n",
      "Average timesteps per episode: 13.413\n",
      "Average penalties per episode: 0.123\n",
      "Average reward per episode: 20.0\n"
     ]
    }
   ],
   "source": [
    "# shows learned process and achieved average performance\n",
    "total_episodes, total_penalties, total_rewards = 0, 0,0\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "for _ in range(epochs):\n",
    "    state = env.reset()\n",
    "    episodes, penalties, reward = 0, 0, 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        if random.uniform(0,1) < 0.1*epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(qTable[state])\n",
    "        state, reward, done, _ = env.step(action)\n",
    "\n",
    "        if reward == -10:\n",
    "            penalties += 1\n",
    "            \n",
    "        episodes +=1\n",
    "\n",
    "    total_penalties += penalties\n",
    "    total_episodes += episodes\n",
    "    total_rewards += reward\n",
    "\n",
    "    \n",
    "print(f\"Results after {epochs} episodes:\")\n",
    "print(f\"Average timesteps per episode: {total_episodes / epochs}\")\n",
    "print(f\"Average penalties per episode: {total_penalties / epochs}\")\n",
    "print(f\"Average reward per episode: {total_rewards / epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CartPole\n",
    "![screenshot of Environment](Screenshot_Cartpole.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "alpha = 0.5\n",
    "min_alpha = 0.1\n",
    "lr = 1.0\n",
    "epsilon = 0.5\n",
    "min_epsilon = 0.1\n",
    "epochs = 1000\n",
    "\n",
    "# start Environment\n",
    "env = gym.make(\"CartPole-v1\").env\n",
    "observation=env.reset()\n",
    "\n",
    "qTable=np.zeros(tuple([1,1,6,12])+ (env.action_space.n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# render() the Environment once\n",
    "# doesn't close automatically \n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to close the render() of cell before\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frames):\n",
    "    plt.plot(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# update epsilon, uses logaritmic decrease\n",
    "def get_epsilon(epoche):\n",
    "    return max(min_epsilon, min(1., 1.0 - math.log10((epoche+1)/25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update alpha, uses logaritmic decrease\n",
    "def get_alpha(epoche):\n",
    "    return max(min_alpha, min(1.,1.0 - math.log10((epoche+1)/25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 25 timesteps.\n",
      "Mean is: 0.0\n",
      "Episode finished after 20 timesteps.\n",
      "Mean is: 0.5\n",
      "Episode finished after 27 timesteps.\n",
      "Mean is: 1.0\n",
      "Episode finished after 23 timesteps.\n",
      "Mean is: 1.5\n",
      "Episode finished after 20 timesteps.\n",
      "Mean is: 2.0\n",
      "Episode finished after 16 timesteps.\n",
      "Mean is: 2.5\n",
      "Episode finished after 26 timesteps.\n",
      "Mean is: 3.0\n",
      "Episode finished after 22 timesteps.\n",
      "Mean is: 3.5\n",
      "Episode finished after 16 timesteps.\n",
      "Mean is: 4.0\n",
      "Episode finished after 19 timesteps.\n",
      "Mean is: 4.5\n",
      "Episode finished after 30 timesteps.\n",
      "Mean is: 5.0\n",
      "Episode finished after 30 timesteps.\n",
      "Mean is: 5.5\n",
      "Episode finished after 15 timesteps.\n",
      "Mean is: 6.0\n",
      "Episode finished after 45 timesteps.\n",
      "Mean is: 6.5\n",
      "Episode finished after 26 timesteps.\n",
      "Mean is: 7.0\n",
      "Episode finished after 13 timesteps.\n",
      "Mean is: 7.5\n",
      "Episode finished after 20 timesteps.\n",
      "Mean is: 8.0\n",
      "Episode finished after 19 timesteps.\n",
      "Mean is: 8.5\n",
      "Episode finished after 16 timesteps.\n",
      "Mean is: 9.0\n",
      "Episode finished after 24 timesteps.\n",
      "Mean is: 9.5\n",
      "Episode finished after 17 timesteps.\n",
      "Mean is: 10.0\n",
      "Episode finished after 12 timesteps.\n",
      "Mean is: 10.5\n",
      "Episode finished after 21 timesteps.\n",
      "Mean is: 11.0\n",
      "Episode finished after 17 timesteps.\n",
      "Mean is: 11.5\n",
      "Episode finished after 15 timesteps.\n",
      "Mean is: 12.0\n",
      "Episode finished after 12 timesteps.\n",
      "Mean is: 12.5\n",
      "Episode finished after 14 timesteps.\n",
      "Mean is: 13.0\n",
      "Episode finished after 11 timesteps.\n",
      "Mean is: 13.5\n",
      "Episode finished after 24 timesteps.\n",
      "Mean is: 14.0\n",
      "Episode finished after 13 timesteps.\n",
      "Mean is: 14.5\n",
      "Episode finished after 24 timesteps.\n",
      "Mean is: 15.0\n",
      "Episode finished after 16 timesteps.\n",
      "Mean is: 15.5\n",
      "Episode finished after 35 timesteps.\n",
      "Mean is: 16.0\n",
      "Episode finished after 16 timesteps.\n",
      "Mean is: 16.5\n",
      "Episode finished after 20 timesteps.\n",
      "Mean is: 17.0\n",
      "Episode finished after 47 timesteps.\n",
      "Mean is: 17.5\n",
      "Episode finished after 23 timesteps.\n",
      "Mean is: 18.0\n",
      "Episode finished after 32 timesteps.\n",
      "Mean is: 18.5\n",
      "Episode finished after 14 timesteps.\n",
      "Mean is: 19.0\n",
      "Episode finished after 17 timesteps.\n",
      "Mean is: 19.5\n",
      "Episode finished after 16 timesteps.\n",
      "Mean is: 20.0\n",
      "Episode finished after 10 timesteps.\n",
      "Mean is: 20.5\n",
      "Episode finished after 21 timesteps.\n",
      "Mean is: 21.0\n",
      "Episode finished after 20 timesteps.\n",
      "Mean is: 21.5\n",
      "Episode finished after 19 timesteps.\n",
      "Mean is: 22.0\n",
      "Episode finished after 12 timesteps.\n",
      "Mean is: 22.5\n",
      "Episode finished after 7 timesteps.\n",
      "Mean is: 23.0\n",
      "Episode finished after 15 timesteps.\n",
      "Mean is: 23.5\n",
      "Episode finished after 16 timesteps.\n",
      "Mean is: 24.0\n",
      "Episode finished after 57 timesteps.\n",
      "Mean is: 24.5\n",
      "Episode finished after 28 timesteps.\n",
      "Mean is: 25.0\n",
      "Episode finished after 34 timesteps.\n",
      "Mean is: 25.5\n",
      "Episode finished after 13 timesteps.\n",
      "Mean is: 26.0\n",
      "Episode finished after 24 timesteps.\n",
      "Mean is: 26.5\n",
      "Episode finished after 9 timesteps.\n",
      "Mean is: 27.0\n",
      "Episode finished after 15 timesteps.\n",
      "Mean is: 27.5\n",
      "Episode finished after 46 timesteps.\n",
      "Mean is: 28.0\n",
      "Episode finished after 30 timesteps.\n",
      "Mean is: 28.5\n",
      "Episode finished after 13 timesteps.\n",
      "Mean is: 29.0\n",
      "Episode finished after 36 timesteps.\n",
      "Mean is: 29.5\n",
      "Episode finished after 36 timesteps.\n",
      "Mean is: 30.0\n",
      "Episode finished after 39 timesteps.\n",
      "Mean is: 30.5\n",
      "Episode finished after 25 timesteps.\n",
      "Mean is: 31.0\n",
      "Episode finished after 35 timesteps.\n",
      "Mean is: 31.5\n",
      "Episode finished after 12 timesteps.\n",
      "Mean is: 32.0\n",
      "Episode finished after 13 timesteps.\n",
      "Mean is: 32.5\n",
      "Episode finished after 25 timesteps.\n",
      "Mean is: 33.0\n",
      "Episode finished after 22 timesteps.\n",
      "Mean is: 33.5\n",
      "Episode finished after 16 timesteps.\n",
      "Mean is: 34.0\n",
      "Episode finished after 17 timesteps.\n",
      "Mean is: 34.5\n",
      "Episode finished after 38 timesteps.\n",
      "Mean is: 35.0\n",
      "Episode finished after 21 timesteps.\n",
      "Mean is: 35.5\n",
      "Episode finished after 26 timesteps.\n",
      "Mean is: 36.0\n",
      "Episode finished after 18 timesteps.\n",
      "Mean is: 36.5\n",
      "Episode finished after 14 timesteps.\n",
      "Mean is: 37.0\n",
      "Episode finished after 46 timesteps.\n",
      "Mean is: 37.5\n",
      "Episode finished after 73 timesteps.\n",
      "Mean is: 38.0\n",
      "Episode finished after 55 timesteps.\n",
      "Mean is: 38.5\n",
      "Episode finished after 163 timesteps.\n",
      "Mean is: 39.0\n",
      "Episode finished after 134 timesteps.\n",
      "Mean is: 39.5\n",
      "Episode finished after 50 timesteps.\n",
      "Mean is: 40.0\n",
      "Episode finished after 24 timesteps.\n",
      "Mean is: 40.5\n",
      "Episode finished after 20 timesteps.\n",
      "Mean is: 41.0\n",
      "Episode finished after 38 timesteps.\n",
      "Mean is: 41.5\n",
      "Episode finished after 42 timesteps.\n",
      "Mean is: 42.0\n",
      "Episode finished after 132 timesteps.\n",
      "Mean is: 42.5\n",
      "Episode finished after 23 timesteps.\n",
      "Mean is: 43.0\n",
      "Episode finished after 29 timesteps.\n",
      "Mean is: 43.5\n",
      "Episode finished after 26 timesteps.\n",
      "Mean is: 44.0\n",
      "Episode finished after 119 timesteps.\n",
      "Mean is: 44.5\n",
      "Episode finished after 29 timesteps.\n",
      "Mean is: 45.0\n",
      "Episode finished after 66 timesteps.\n",
      "Mean is: 45.5\n",
      "Episode finished after 35 timesteps.\n",
      "Mean is: 46.0\n",
      "Episode finished after 132 timesteps.\n",
      "Mean is: 46.5\n",
      "Episode finished after 69 timesteps.\n",
      "Mean is: 47.0\n",
      "Episode finished after 36 timesteps.\n",
      "Mean is: 47.5\n",
      "Episode finished after 110 timesteps.\n",
      "Mean is: 48.0\n",
      "Episode finished after 29 timesteps.\n",
      "Mean is: 48.5\n",
      "Episode finished after 22 timesteps.\n",
      "Mean is: 49.0\n",
      "Episode finished after 64 timesteps.\n",
      "Mean is: 49.5\n",
      "Episode finished after 17 timesteps.\n",
      "Mean is: 50.0\n",
      "Episode finished after 108 timesteps.\n",
      "Mean is: 50.5\n",
      "Episode finished after 46 timesteps.\n",
      "Mean is: 51.0\n",
      "Episode finished after 177 timesteps.\n",
      "Mean is: 51.5\n",
      "Episode finished after 18 timesteps.\n",
      "Mean is: 52.0\n",
      "Episode finished after 182 timesteps.\n",
      "Mean is: 52.5\n",
      "Episode finished after 49 timesteps.\n",
      "Mean is: 53.0\n",
      "Episode finished after 20 timesteps.\n",
      "Mean is: 53.5\n",
      "Episode finished after 26 timesteps.\n",
      "Mean is: 54.0\n",
      "Episode finished after 11 timesteps.\n",
      "Mean is: 54.5\n",
      "Episode finished after 58 timesteps.\n",
      "Mean is: 55.0\n",
      "Episode finished after 20 timesteps.\n",
      "Mean is: 55.5\n",
      "Episode finished after 24 timesteps.\n",
      "Mean is: 56.0\n",
      "Episode finished after 27 timesteps.\n",
      "Mean is: 56.5\n",
      "Episode finished after 155 timesteps.\n",
      "Mean is: 57.0\n",
      "Episode finished after 77 timesteps.\n",
      "Mean is: 57.5\n",
      "Episode finished after 153 timesteps.\n",
      "Mean is: 58.0\n",
      "Episode finished after 123 timesteps.\n",
      "Mean is: 58.5\n",
      "Episode finished after 172 timesteps.\n",
      "Mean is: 59.0\n",
      "Episode finished after 33 timesteps.\n",
      "Mean is: 59.5\n",
      "Episode finished after 45 timesteps.\n",
      "Mean is: 60.0\n",
      "Episode finished after 20 timesteps.\n",
      "Mean is: 60.5\n",
      "Episode finished after 26 timesteps.\n",
      "Mean is: 61.0\n",
      "Episode finished after 33 timesteps.\n",
      "Mean is: 61.5\n",
      "Episode finished after 37 timesteps.\n",
      "Mean is: 62.0\n",
      "Episode finished after 67 timesteps.\n",
      "Mean is: 62.5\n",
      "Episode finished after 31 timesteps.\n",
      "Mean is: 63.0\n",
      "Episode finished after 142 timesteps.\n",
      "Mean is: 63.5\n",
      "Episode finished after 28 timesteps.\n",
      "Mean is: 64.0\n",
      "Episode finished after 90 timesteps.\n",
      "Mean is: 64.5\n",
      "Episode finished after 23 timesteps.\n",
      "Mean is: 65.0\n",
      "Episode finished after 63 timesteps.\n",
      "Mean is: 65.5\n",
      "Episode finished after 35 timesteps.\n",
      "Mean is: 66.0\n",
      "Episode finished after 52 timesteps.\n",
      "Mean is: 66.5\n",
      "Episode finished after 207 timesteps.\n",
      "Mean is: 67.0\n",
      "Episode finished after 295 timesteps.\n",
      "Mean is: 67.5\n",
      "Episode finished after 133 timesteps.\n",
      "Mean is: 68.0\n",
      "Episode finished after 78 timesteps.\n",
      "Mean is: 68.5\n",
      "Episode finished after 189 timesteps.\n",
      "Mean is: 69.0\n",
      "Episode finished after 181 timesteps.\n",
      "Mean is: 69.5\n",
      "Episode finished after 43 timesteps.\n",
      "Mean is: 70.0\n",
      "Episode finished after 30 timesteps.\n",
      "Mean is: 70.5\n",
      "Episode finished after 49 timesteps.\n",
      "Mean is: 71.0\n",
      "Episode finished after 24 timesteps.\n",
      "Mean is: 71.5\n",
      "Episode finished after 134 timesteps.\n",
      "Mean is: 72.0\n",
      "Episode finished after 348 timesteps.\n",
      "Mean is: 72.5\n",
      "Episode finished after 158 timesteps.\n",
      "Mean is: 73.0\n",
      "Episode finished after 446 timesteps.\n",
      "Mean is: 73.5\n",
      "Episode finished after 261 timesteps.\n",
      "Mean is: 74.00671140939598\n",
      "Episode finished after 442 timesteps.\n",
      "Mean is: 74.51333333333334\n",
      "Episode finished after 19 timesteps.\n",
      "Mean is: 75.01986754966887\n",
      "Episode finished after 359 timesteps.\n",
      "Mean is: 75.52631578947368\n",
      "Episode finished after 366 timesteps.\n",
      "Mean is: 76.0326797385621\n",
      "Episode finished after 157 timesteps.\n",
      "Mean is: 76.57792207792208\n",
      "Episode finished after 24 timesteps.\n",
      "Mean is: 77.12258064516129\n",
      "Episode finished after 37 timesteps.\n",
      "Mean is: 77.66666666666667\n",
      "Episode finished after 343 timesteps.\n",
      "Mean is: 78.21019108280255\n",
      "Episode finished after 134 timesteps.\n",
      "Mean is: 78.75316455696202\n",
      "Episode finished after 271 timesteps.\n",
      "Mean is: 79.29559748427673\n",
      "Episode finished after 213 timesteps.\n",
      "Mean is: 79.8375\n",
      "Episode finished after 219 timesteps.\n",
      "Mean is: 80.37888198757764\n",
      "Episode finished after 331 timesteps.\n",
      "Mean is: 80.91975308641975\n",
      "Episode finished after 219 timesteps.\n",
      "Mean is: 81.4601226993865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 205 timesteps.\n",
      "Mean is: 82.0\n",
      "Episode finished after 103 timesteps.\n",
      "Mean is: 82.53939393939395\n",
      "Episode finished after 22 timesteps.\n",
      "Mean is: 83.07831325301204\n",
      "Episode finished after 38 timesteps.\n",
      "Mean is: 83.61676646706587\n",
      "Episode finished after 31 timesteps.\n",
      "Mean is: 84.1547619047619\n",
      "Episode finished after 54 timesteps.\n",
      "Mean is: 84.6923076923077\n",
      "Episode finished after 56 timesteps.\n",
      "Mean is: 85.22941176470589\n",
      "Episode finished after 44 timesteps.\n",
      "Mean is: 85.76608187134502\n",
      "Episode finished after 207 timesteps.\n",
      "Mean is: 86.30232558139535\n",
      "Episode finished after 258 timesteps.\n",
      "Mean is: 86.83815028901734\n",
      "Episode finished after 219 timesteps.\n",
      "Mean is: 87.3735632183908\n",
      "Episode finished after 131 timesteps.\n",
      "Mean is: 87.90857142857143\n",
      "Episode finished after 122 timesteps.\n",
      "Mean is: 88.44318181818181\n",
      "Episode finished after 102 timesteps.\n",
      "Mean is: 88.9774011299435\n",
      "Episode finished after 171 timesteps.\n",
      "Mean is: 89.51123595505618\n",
      "Episode finished after 239 timesteps.\n",
      "Mean is: 90.04469273743017\n",
      "Episode finished after 124 timesteps.\n",
      "Mean is: 90.57777777777778\n",
      "Episode finished after 162 timesteps.\n",
      "Mean is: 91.11049723756906\n",
      "Episode finished after 205 timesteps.\n",
      "Mean is: 91.64285714285714\n",
      "Episode finished after 162 timesteps.\n",
      "Mean is: 92.17486338797814\n",
      "Episode finished after 198 timesteps.\n",
      "Mean is: 92.70652173913044\n",
      "Episode finished after 309 timesteps.\n",
      "Mean is: 93.23783783783784\n",
      "Episode finished after 145 timesteps.\n",
      "Mean is: 93.76881720430107\n",
      "Episode finished after 201 timesteps.\n",
      "Mean is: 94.29946524064171\n",
      "Episode finished after 221 timesteps.\n",
      "Mean is: 94.82978723404256\n",
      "Episode finished after 136 timesteps.\n",
      "Mean is: 95.35978835978835\n",
      "Episode finished after 177 timesteps.\n",
      "Mean is: 95.88947368421053\n",
      "Episode finished after 202 timesteps.\n",
      "Mean is: 96.41884816753927\n",
      "Episode finished after 239 timesteps.\n",
      "Mean is: 96.94791666666667\n",
      "Episode finished after 165 timesteps.\n",
      "Mean is: 97.47668393782384\n",
      "Episode finished after 271 timesteps.\n",
      "Mean is: 98.00515463917526\n",
      "Episode finished after 215 timesteps.\n",
      "Mean is: 98.53333333333333\n",
      "Episode finished after 150 timesteps.\n",
      "Mean is: 99.06122448979592\n",
      "Episode finished after 202 timesteps.\n",
      "Mean is: 99.58883248730965\n",
      "Episode finished after 226 timesteps.\n",
      "Mean is: 100.11616161616162\n",
      "Episode finished after 195 timesteps.\n",
      "Mean is: 100.64321608040201\n",
      "Episode finished after 203 timesteps.\n",
      "Mean is: 101.17\n",
      "Episode finished after 250 timesteps.\n",
      "Mean is: 101.69651741293532\n",
      "Episode finished after 98 timesteps.\n",
      "Mean is: 102.22277227722772\n",
      "Episode finished after 38 timesteps.\n",
      "Mean is: 102.7487684729064\n",
      "Episode finished after 31 timesteps.\n",
      "Mean is: 103.27450980392157\n",
      "Episode finished after 40 timesteps.\n",
      "Mean is: 103.8\n",
      "Episode finished after 274 timesteps.\n",
      "Mean is: 104.3252427184466\n",
      "Episode finished after 167 timesteps.\n",
      "Mean is: 104.85024154589372\n",
      "Episode finished after 200 timesteps.\n",
      "Mean is: 105.375\n",
      "Episode finished after 228 timesteps.\n",
      "Mean is: 105.89952153110048\n",
      "Episode finished after 244 timesteps.\n",
      "Mean is: 106.42380952380952\n",
      "Episode finished after 180 timesteps.\n",
      "Mean is: 106.9478672985782\n",
      "Episode finished after 153 timesteps.\n",
      "Mean is: 107.47169811320755\n",
      "Episode finished after 406 timesteps.\n",
      "Mean is: 107.99530516431925\n",
      "Episode finished after 159 timesteps.\n",
      "Mean is: 108.51869158878505\n",
      "Episode finished after 330 timesteps.\n",
      "Mean is: 109.04186046511627\n",
      "Episode finished after 372 timesteps.\n",
      "Mean is: 109.56481481481481\n",
      "Episode finished after 243 timesteps.\n",
      "Mean is: 110.08755760368663\n",
      "Episode finished after 258 timesteps.\n",
      "Mean is: 110.61009174311927\n",
      "Episode finished after 226 timesteps.\n",
      "Mean is: 111.1324200913242\n",
      "Episode finished after 29 timesteps.\n",
      "Mean is: 111.65454545454546\n",
      "Episode finished after 47 timesteps.\n",
      "Mean is: 112.17647058823529\n",
      "Episode finished after 28 timesteps.\n",
      "Mean is: 112.6981981981982\n",
      "Episode finished after 70 timesteps.\n",
      "Mean is: 113.21973094170404\n",
      "Episode finished after 133 timesteps.\n",
      "Mean is: 113.74107142857143\n",
      "Episode finished after 290 timesteps.\n",
      "Mean is: 114.26222222222222\n",
      "Episode finished after 258 timesteps.\n",
      "Mean is: 114.78318584070796\n",
      "Episode finished after 173 timesteps.\n",
      "Mean is: 115.30396475770925\n",
      "Episode finished after 369 timesteps.\n",
      "Mean is: 115.82456140350877\n",
      "Episode finished after 178 timesteps.\n",
      "Mean is: 116.34497816593887\n",
      "Episode finished after 51 timesteps.\n",
      "Mean is: 116.86521739130434\n",
      "Episode finished after 30 timesteps.\n",
      "Mean is: 117.38528138528139\n",
      "Episode finished after 466 timesteps.\n",
      "Mean is: 117.91810344827586\n",
      "Episode finished after 383 timesteps.\n",
      "Mean is: 118.48068669527898\n",
      "Episode finished after 463 timesteps.\n",
      "Mean is: 119.05128205128206\n",
      "Episode finished after 383 timesteps.\n",
      "Mean is: 119.71063829787234\n",
      "Episode finished after 267 timesteps.\n",
      "Mean is: 120.36864406779661\n",
      "Episode finished after 469 timesteps.\n",
      "Mean is: 121.042194092827\n",
      "Episode finished after 415 timesteps.\n",
      "Mean is: 121.77731092436974\n",
      "Episode finished after 325 timesteps.\n",
      "Mean is: 122.53138075313808\n",
      "Episode finished after 479 timesteps.\n",
      "Mean is: 123.33333333333333\n",
      "Episode finished after 467 timesteps.\n",
      "Mean is: 124.25726141078839\n",
      "Episode finished after 449 timesteps.\n",
      "Mean is: 125.21900826446281\n",
      "Episode finished after 496 timesteps.\n",
      "Mean is: 126.20576131687243\n",
      "Episode finished after 242 timesteps.\n",
      "Mean is: 127.20491803278688\n",
      "Episode finished after 146 timesteps.\n",
      "Mean is: 128.2\n",
      "Episode finished after 174 timesteps.\n",
      "Mean is: 129.1910569105691\n",
      "Episode finished after 218 timesteps.\n",
      "Mean is: 130.17813765182186\n",
      "Episode finished after 188 timesteps.\n",
      "Mean is: 131.16129032258064\n",
      "Episode finished after 228 timesteps.\n",
      "Mean is: 132.140562248996\n",
      "Episode finished after 430 timesteps.\n",
      "Mean is: 133.116\n",
      "Episode finished after 307 timesteps.\n",
      "Mean is: 134.22310756972112\n",
      "Episode finished after 439 timesteps.\n",
      "Mean is: 135.40873015873015\n",
      "Episode finished after 462 timesteps.\n",
      "Mean is: 136.74703557312253\n",
      "Episode finished after 150 timesteps.\n",
      "Mean is: 138.12992125984252\n",
      "Episode finished after 379 timesteps.\n",
      "Mean is: 139.71372549019608\n",
      "Episode finished after 439 timesteps.\n",
      "Mean is: 141.31640625\n",
      "Episode finished after 386 timesteps.\n",
      "Mean is: 142.9182879377432\n",
      "Episode finished after 447 timesteps.\n",
      "Mean is: 144.55426356589146\n",
      "Episode finished after 477 timesteps.\n",
      "Mean is: 146.22007722007723\n",
      "Episode finished after 471 timesteps.\n",
      "Mean is: 147.9923076923077\n",
      "Episode finished after 451 timesteps.\n",
      "Mean is: 149.8007662835249\n",
      "Episode finished after 456 timesteps.\n",
      "Mean is: 151.69847328244273\n",
      "Episode finished after 338 timesteps.\n",
      "Mean is: 153.6045627376426\n",
      "Episode finished after 185 timesteps.\n",
      "Mean is: 155.53030303030303\n",
      "Episode finished after 460 timesteps.\n",
      "Mean is: 157.47924528301886\n",
      "Episode finished after 311 timesteps.\n",
      "Mean is: 159.4699248120301\n",
      "Episode finished after 480 timesteps.\n",
      "Mean is: 161.4494382022472\n",
      "Episode finished after 469 timesteps.\n",
      "Mean is: 163.4962686567164\n",
      "Episode finished after 332 timesteps.\n",
      "Mean is: 165.56877323420073\n",
      "Episode finished after 497 timesteps.\n",
      "Mean is: 167.64444444444445\n",
      "Episode finished after 382 timesteps.\n",
      "Mean is: 169.72693726937268\n",
      "Episode finished after 498 timesteps.\n",
      "Mean is: 171.86029411764707\n",
      "Episode finished after 490 timesteps.\n",
      "Mean is: 174.08058608058607\n",
      "Episode finished after 484 timesteps.\n",
      "Mean is: 176.32846715328466\n",
      "Episode finished after 321 timesteps.\n",
      "Mean is: 178.56363636363636\n",
      "Episode finished after 424 timesteps.\n",
      "Mean is: 180.84782608695653\n",
      "Episode finished after 468 timesteps.\n",
      "Mean is: 183.1263537906137\n",
      "Episode finished after 443 timesteps.\n",
      "Mean is: 185.42805755395685\n",
      "Episode finished after 391 timesteps.\n",
      "Mean is: 187.7168458781362\n",
      "Episode finished after 459 timesteps.\n",
      "Mean is: 190.0\n",
      "Episode finished after 430 timesteps.\n",
      "Mean is: 192.355871886121\n",
      "Episode finished after 277 timesteps.\n",
      "Mean is: 194.87943262411346\n",
      "Episode finished after 485 timesteps.\n",
      "Mean is: 197.3886925795053\n",
      "Episode finished after 393 timesteps.\n",
      "Mean is: 199.8943661971831\n",
      "Episode finished after 443 timesteps.\n",
      "Mean is: 202.3859649122807\n",
      "Episode finished after 487 timesteps.\n",
      "Mean is: 204.86713286713288\n",
      "Episode finished after 413 timesteps.\n",
      "Mean is: 207.33449477351917\n",
      "Episode finished after 399 timesteps.\n",
      "Mean is: 209.80902777777777\n",
      "Episode finished after 489 timesteps.\n",
      "Mean is: 212.3425605536332\n",
      "Episode finished after 456 timesteps.\n",
      "Mean is: 214.87586206896552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 387 timesteps.\n",
      "Mean is: 217.44329896907217\n",
      "Episode finished after 388 timesteps.\n",
      "Mean is: 220.03082191780823\n",
      "Episode finished after 356 timesteps.\n",
      "Mean is: 222.62116040955632\n",
      "Episode finished after 339 timesteps.\n",
      "Mean is: 225.22108843537416\n",
      "Episode finished after 491 timesteps.\n",
      "Mean is: 227.83389830508474\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOy9eZgkR3km/kZm1tHn3Ic0M9KIQRJCAgkhsISwOMVpG9mwNrtYHGaRjfl58fGz8RrbrIFl8cFp1tiAAAEGjMEYcRl0IkuApJGQhO4ZzaG5+5w+68gj9o/MLzIiMrKuruqemYr3eebp7qysrKjq6TfefL83vmCcc1hYWFhYnFpwVnoAFhYWFhbdhyV3CwsLi1MQltwtLCwsTkFYcrewsLA4BWHJ3cLCwuIUhLfSAwCA9evX8+3bt6/0MCwsLCxOKtxzzz0TnPMNpsdOCHLfvn07du7cudLDsLCwsDipwBjbn/eYtWUsLCwsTkFYcrewsLA4BWHJ3cLCwuIUhCV3CwsLi1MQLZE7Y2wfY+znjLH7GGM7k2NrGWM3MMZ2JV/XJMcZY+zjjLHdjLEHGGMX9/INWFhYWFhk0Y5yfxHn/CLO+SXJz38K4CbO+dkAbkp+BoBXAjg7+XcNgE92a7AWFhYWFq1hKbbMawBcl3x/HYCrpONf4DF+CmA1Y+y0JbyOhYWFhUWbaJXcOYAfMsbuYYxdkxzbxDk/AgDJ143J8S0ADkjPPZgcU8AYu4YxtpMxtnN8fLyz0VtYWFj0AJxzcM5x62Nj2DM+v9LD6QitkvvlnPOLEVsu72CMXdHgXGY4lmkazzn/FOf8Es75JRs2GBdYWVhYWAAAPvOfe3DP/qlle70X/t2t+NKdT+LNn7sbL/7Qj5btdbuJlsidc344+ToG4JsAngvgGNktydex5PSDALZJT98K4HC3BmxhYdF/eP93H8FrP/mTZXu9A1OLODC1KH6eqfjL9trdQlNyZ4wNMcZG6HsALwPwIIDrAbwpOe1NAL6VfH89gDcmqZlLAcyQfWNhYWHRLsJoeXeLiyKOiAN+GIljNz96rOuvM7Po479ftxO3PjbW/OQO0Ipy3wTgdsbY/QDuAvBdzvl/APgggCsZY7sAXJn8DADfA7AHwG4Anwbwu10ftYWFRd9gvhYs6+uFydajfhjBdWKX+d9/1rn58MT4PF74t7dgfK6mHK/4IW585BgOH692PtgGaErunPM9nPMLk3/nc87/d3J8knP+Es752cnXqeQ455y/g3O+g3P+DM657QhmYWHRMZad3JM7hXoQie9/9Ph408Jq1Q9x6HgFAHDLo2O4+H03YLEe4HN37MW+yUV8/0HVwAii+M7Ac01lyqXDrlC1sLA4oTFfjcl9qOguy+sFCaEv1kMAwJsuOxMFl+HLdz7Z8Hm/86V7cPkHbwYAPHp0DlMLdUwt1DFUipvv6pNUEMav4zmW3C0sLPoQ87W4mDlQ7G2H8icnFxFGHGFCupWE3E9fPYCz1g/h4HSl4fNvfSyOdAdhhLlqPOZaEGE4GfeCTu7JJOJacrewsOgXRBHH276wE7c8Noa5RLkPLlG5c55fmJ2p+Ljib2/Bu7/5c2GXkHL3XAeu4wgyboZ6GIkxV/0QgyUi91A5jyyfgtsbGrbkbmFhccKh4oe44eFjeMvn7hZ2xlLI/Y7dEzjrf34Pu8fMvnnVj4n3q3cfEKS7WI9ft+gyeA5DGEXG5xJIgNeDVLlX/UhMKlnlHl/PKncLC4u+gayS57ug3H/0eGyZ/NOPnjA+Lsctfc1zL7gOXIc1Ve6eE9NpTO7xmGt+iHoSqVyoW8/dwsKizyGT7ZGZOCpIhclOUEgSKf/x4FGhyPNej1Ixsi1TcFnTvD0p8JpE7tUgRM2PyX1es2VosvCsLWNhYXEqo1IP8fpP/QSPHp0VlgUA/OSJSQBAudC5cp+crwMA5moBHj48m3lcVuV37onbHNAkUHCZotyfGJ/HrmNzmWuQAq+HEWYlW4aU+8xiXTmfJgur3C0sLE4ZzFV9fOzGXQikVaD3PjmNn+6Zwv+6/iFFJd+1b+k9ZSbm6ygmCvnA9GLmcdlPpzsFUu5F14HnOGJMf/Xth/En33ggcw03uTuQbZmqH6IexNee0sid3nuvPPfeZossLCwsDPjQDx/H53+8D2esG8CqgQJedO5GlAsx+Vb9SPjRMqIltCGYXKjhwm2rcPe+aRyYykYaZeVeDWJSrwW0yEj13KcWahibrWWu4Sm2jKTck+tML6j9aQKRlrHK3cLC4hQBEed/7prAb31+J+7eN42S54rHTMXLsEGUkfDebz+Mi993Q+b45HwdW1YPYMNISWkIBgDjczVlMqn5qjde0NIyc9UAE/M15a4DABzGxPMp4VMLQtSSyWK+FojvgdSWcR3ruVtYWJwiKHkx9UwtxFbFfM1Hwo2o+aEgUnlVaivC/bN37BXXlDE5X8O64RK2rRlQFiONzVVx2f+5SaRpgHTiIRRJuScTwFw1QMSByYU6vv/zI/jr/3gUQKrcj1d8MVZZuQPA8cVUvVNjMuu5W1hYnDIgKyL1piOQ7V3xQ/gJke7YOCye06ktU6mHWKiHWDtUxLa1g3jk6Cw+ftMuVP0QM4s+gojjyExK+FVNuXuuAy9Jy3DOheVybLaKt//zvfjkrU+I84C0eEvXqksKX554REHV2jIWFhanCoqJck+X6YfCdqn6oSC+p8rk3oItY8LkQuyPrx8uYtuaQRxf9PHhGx7HXXunhMKmuGL8+qpyj9MycUG1FkRi4jk6k3ZzrAeRUOCT86kfL0chAbUvfNDjtIwtqFpYWCw7aMl9utgn7cAoe+4yuTfLmeseOIGU9LqhktICgDEor0nQlXvBdeAlBVWKOALAMamF79RCXaReJiV1XpOikPq10xWq1nO3sLA4RZAqdyo8puRe9UNB1E9Z37pyPzaXTbAAqXJfN1zEC89Nt/T0w0hcUy50VgOV3Ite7LmHERfjBYCx2VS5T8zXBLlPyMrdD1ELIoyWPfEzwa5QtbBYIdSCEJ/5zz25itCic1DmnFIlshUT8dSyGC17+IOXnoPBotu0oHp0xty1UVbuT9kwjO/+j+cDAPyQC3KvNrBlPIclyj1SyF22ZcYlctc991oQYdVgIXNt67lbWKwQ7to7hfd/9xHcf3BmpYdyyoGUO6EWRIoyT2OCDO986dl49plrmtoyeTsa0QQykqhnsoRi5U6vLyl3gy2TKvfYlmEsvlOg9zExV0s99+ROYaTsibTMqoGY3CvStX3pPfYCltwtLHJAt837Jhaw/U+/i59bku8a9Da3tSBUyFvvu+I6rGHLXkBV0jJopelAEqtUyT2r3Guaci96qedOyn3L6gGMz9UwnPS7mVyoZ9IyG4ZLqAUh6kGI0TIpdynnntwRFqznbmGxvKA//BsejjdH/pedjXfisWgdulqVC6pAWhwlNeww1nQR02HNlnnw0Az+6tsPYbEewGFptp5imH7IRbxSLqjWw6wt4zoOgjBV7qevGsBCLRBtfifmUltmOmkzsHaoiKofxbaMQbmLzTqsLWNhsbwgrqHFJrQC0aIL0HhaLqgC2V2KHMbQrPQxW0n9cM45bnzkGD53xz6Mz9UwWPTAkt9fI1tGt4sAoODFOXfZc9+0qozFeiB2a5KLqBGPF18NFF1Ug7i3TKrc0zfR6yikJXcLixwQ2ZA3asm9e+Aau1f9UFHmpKQLwpZpvJMSAKWTZMQhEW9dWDLyNQOpoEpWTNlA7kXJc58lch8pYb4WCCU+MV9XFlkNlz2UPFd0hSwVHJQLjmrLCHK3toyFxbKCyMRPiMZye/eg10ZrQaSQ42yy2EdV7mZyDyMOP1SbjYURF177xHwNA1K7YE/YMpFky8TnmtoKp2mZ2JYZLnkYKRfiVbXJS07M15TJaajkoVxwUPPjRUwlz0G54C5rFNIuYrKwyAH94ZIitMq9e9BFeC0IlWZhtFhIeO4Oy825v/fbD2Hf5KLw1IG4XiLIfa6G0cTzBtIYZl22ZRLlXiqoepexeIKJC7rxCtORsoehkjoJTC7UcbpXFj8PlzxB5vUwQtFzMFBwxd0EEP+/Yix+b72AVe4WFjkgMqmHZMus5GhOLehErUchyT+XlXteEvLQ8QoOTi8qkwPnQMWPrzE+X8u1ZUKxiCkhd08l7YLrgDEmJpmZRSJ3TzqHoa51shwqxsp9oR6ngIquG5N9oHruvUrKAJbcLSxyQWRDyY1eKax+hM7T8iImIO3BIjx3lt9+IIw4gsSaIcjK3Q+5sv+q6zAwpkYhKSFT1pR7IfmdU4uA6cU6RsoFhdyHSx7CiCvjGyp5KHuuuAMpJraMrNzDiPcs4w5YcrewyAX94du0TPehF0f1tAyRotuCLRPyWIXLnrtM7gAwUFAd6ILrwA95ZhxlXbknVg8p97lqgIGCq7QiHi57CCL1zmO4FCt1OhR77o6yWMoPo5757YAldwuLXFD4IrC2TNeR8dy1nDsVVOWce17L3zCKEyl5aRkAii0DxIrcD6NMvFIvqNKdAxVhK36Ioudoyr0QWzyZtExKrybPPYx4z1oPAJbcLSxyofuxVrl3D1nPXY1CirRMQn5uA889jDiCMG3FC8R3BrTBNQAM6qTtOQjCKDOOPFuGJplKPUTRdcTKVCBW6UHElfENJQVVAtkyclOyIOI96wgJWHK3sMgF3bKTImSW3LsGnajjzToMnntCfo6Tv81eFCW2TBvK3XMc1A22TKag6lHOPv5a8UMUPEfx8Ino5R2XhpOCanpdQ1rG2jIWFiuDdIWqtWW6DZPnLqdNFhISdFuxZTiPbRnNc5eX+g9q5F50zbaMHoUUtowj2TKach9JVp/KLQyGSmqipuQ5KBWczApVa8tYWKwAxApVa8t0Haacu+xZk8JVPPcc5R6Y0jKRWlDVyd1kyzgszcATPJGWYWLcRY8pxD0klHv6esMlT9lohDx3fYWqVe4WFisAsUJVLGJaydGsPG7fNYGxOXPnxXahtx/Qc+7U7MuRyDUvChklMUTZc/eTLfEIeqHUc5jSz51eQ1fS1GtGPl5wHWXFK7US1pX7OZtGxM8lz41tGW2F6gkRhWSMuYyxnzHGvpP8fBZj7E7G2C7G2L8wxorJ8VLy8+7k8e29GbqFRW8hVqgmpNHvnvtvXXc3vnxndzpj6jytLwKKuNpzxWEso/YJRPoycS7WAuWcwaIpChllyd0x2zIyCRddB47DRBxyhJS7dOcwXM4pqPqhUsvRWx93E+1c+Z0AHpF+/msAH+Gcnw1gGsBbk+NvBTDNOX8qgI8k51lYnHQQi5hs4zBwzlEPIkWdLu166fdEkmTF0McsE6rDGhRUqSd7PRR3V/MZcs9GHOPeMukxz3FEO+D0mJqWAdIiK9kx9FUe3nDSnoDeW9F1MJDsJkWTwAmxiIkxthXAqwF8JvmZAXgxgK8np1wH4Krk+9ckPyN5/CWs3yWPxUkJ3QboZ1uGPoq8omb710uvQ73OafNqii3KhOo2WMREk+9ikkGXr0XI5NzduBFYqCl3PZpY1NIyQOrLD5U8OCw7cdBjALAj8d1rQSRy71RU9cMTw3P/KIA/AUDz3DoAxznnND0eBLAl+X4LgAMAkDw+k5yvgDF2DWNsJ2Ns5/j4eIfDt7DoHXQu6aXKOtFBxNpsk+pOMCo2sojphIhY9rkZY4rKVsaWkHvcw0Xdm5V+ZToBe66DehApqR3PYUK50/P0tAyQEv5QKfbRPYO1MpTYQH/zumfieTvW4YIto+J9UVE1XsS0grYMY+yXAIxxzu+RDxtO5S08lh7g/FOc80s455ds2LDB8BQLi5WFTmT9fAMaCgLtzvXkOwAi98XEVim6WbXsNsi5y8eLSU59ISH3dcMlAFAKoED8GvJmHfFrpJ77gHb3IE/sNAHEzcFco/qmqOTTNo/iy2+7FINFT7Q2IHIPoqingqGVlr+XA/gVxtirAJQBjCJW8qsZY16izrcCOJycfxDANgAHGWMegFUApro+cguLHkMnkz4W7uIuplvKXb4K7VK0UAvhOQ5KJlumQRRSts/I+lhIVqeuHy5hfK6Wb8tEqnKnu4WBoouFepjpLQOotky54CoEPVR0wRjDcDlLrTQGKvwGITfu/NQtNL0y5/x/cs63cs63A3g9gJs5528AcAuA1yWnvQnAt5Lvr09+RvL4zbzZFioWFicg9P+1fcztYqLrFrnL1xkdiIlwsR7AcWTlrtoynJt3Y5IJmsiSbJkNI7Fy19MyJlvGdVNbhlaqmsZChH/u5hGcu3lEKcK+4dIz8YM/uMKYgqEVq48fmwfnPGk/sLLKPQ/vAvBVxtj7AfwMwLXJ8WsBfJExthuxYn/90oZoYbEy0IuH/axQQsnX7gZkjl4l2TIuY4KgZdIkEox43P7XNDYgJeP5Kin3IgDTClXHoNwdYQXRSlWRlnGzyv1dr3gagHQDdSC2c7asHjC+Z4pG/o+v/AybRkoII97TKGRb5M45vxXArcn3ewA813BOFcB/6cLYLCxWFLot08/3n7zLyp0b0jKVegjXYcJa0aOQgDk+GPGscifP/cKtq3Hb4+PiNQhe0n5Anqsclk4oBcdB0XUyvWXk1xDXcrKTkAkXbVuNF527Abc8No79U4vww9567naFqoVFDnSR2oukyMkCUrh5iZV2IX+Sp6+Kle5CPYDrpMpdWcQklHtjW6YkbJnY177qoi3Y+edXGlv5+tqqWM9xxGu6SXJG7wpJz5Xhtkjug0UPn/hvFwMAphbqPW8/YPdQtbDIgS0VpSD+zEustH+9WIF//52/KHrCVP1IJXdXLajS83QEBs+dlLteSCUUXAY/ym8/4LkMf3DlOXj2mWvEY+I19P4zrnyH0ZisB4suSp6DaSL3E8WWsbDoJ+hE0s/KXeTcu+i5Oww4Z9MIHj82ByBuHjZQcIX69pwsaZo8/8hA7hU/BGNZC4VQMEQhPamg6joM//0Xn5I+Ziiopo+pkc1GYIxh3VARkwt1+JFt+WthsSLQM919zO2pLdM15Q6wJH9ENkfNj8mOsuqK5y4VVDNjkz132vw6ioTaN6HgOpndk+QVqjrpNlLurmESaoQ1Q8XYljlRGodZWPQbdFumS6L1pASROjVe/PhNu5SUSLvg4KKHDKnlehjBcZggT7VxWDIOo3JPvyel7oe84YbmnstQDw0rVA2LlvSxFD31MTnV04oSX5uQexDxTC+bbsKSu4VFDnSVqrep7ScQgRK5fviGx/G2L+xs+flHZ6r42t0HxM+cQyJ32dbI8dwT0jR5/vIOTPTcIGys3Isu9XNPj8Wee3ZiAdLt/vTxymPTv8+DTO5WuVtYrADybJl79k8rmy70A+TeMp0Umq+//xD+5BsPiEIn51xYGAq5s7wopLmgyrm6dyk9txlxeo6DiEPZ4MNzHDGh6M8tyLZMA8+90d0CYe1QEdML9WSbvROj5a+FRV8hU1CNOH66ZxKv/eSP8enb9qzQqFYGpJhDbROMVkEbaQTCu09X/OqLlRoVVPUopu7SkKXjh6ntY0IhsVbk9+I6TOzZ2shz15W7KdXTCGsHi5irBaj4oS2oWlisBHSFyoGubVZxsiGSCqqzyebV7UBf4RqnZQzKXbFlsikUfcINNLZXbJkGxEmTgLyptdxbpqHnnrMVH9Cick9WzfohV+yebsOSu4VFDnR/1w8jfPfnRwDA2BjqVIbo586B2erSyT3iqXSXyd1hZuXOcqKQupKnnjBBxBuqaLp2Tdr31HGYsd0AoHruui2jeO4tKnd9HL2AJXcLixzot/wHpytd77FyskB+37PVoMnZWUQ8+7mRcncdJtIwsnI3kaau3PUJOE3LRA1VNGXVa76u3LPtBugx8dyMck9/1icFE9YOyeRuPXcLi2WHbsuoe3z2F7nLBVWyZXR7ohHos5O7S8oiNyVVOQop2x00DvW6+iRL5B42Ue7kreueu2lbPXpMf4107O3l3NcnnSpNr9NNWHK3sMhBpngnEUm3Nq04WaCQe7Xx0n7j84ncw6znDqitdUU/d82uAbJkniF3qaDayHNPC6qpLRPvxJS9awBUuyVvn1XT80zYuibtGmk9dwuLZUYQRplbfrl412/KXbZl5hLPXd/dqKXny8pdelws+2dm5U6kqd9N5Sn3IIrQyPHwjMo9jULqitqRrKOCnoFvc4VqyXNFK2L9Wt2EJXcLCw1375vC+e/5ASbma8pxWa33m+eebpANzFbaV+6BnpaBum0hqXTHgdFzF8q9Sb+fNC3TxJZxczz3nBWq8eMOCi7LePl62qcVbFs72Nb5ncCSu4WFhoPTi6gFEcbndHJPiUD233mHC3tOJqi2TKzc2/GL9YIq1zx3ueVAOzl3fZKl59bDqKGKLhpsGdeVV6hmn+tKto1+PP0+9yUVnGnJ3cJi+UEK3deMdaWgKn3/0g//CNf9eN9yDG3FEEm2ChVUgzbuXjLKnat70pIt4+Tk3EVvmWa2DDUOa5KWMdkyam+ZLDV60tj04wTT80w4IyF3/e6wm7DkbmGhgYiMVlWK4xKxyPbAwekKDkxXlmdwKwThlUccc0lBVZ/8GiHSyD323LO2jMsgbdZh6C3TrKCaPDfejq8FW0ZPy5ByNxQ64z1Ws5TJGBPjayXnDgBnrBsCAOyfXGzp/E5gyd3CQgMRmU5eYY5yjzg/5T140ThMWsQUhK2/Z72gmlXuUlqmYcvfxjl3eq78HBPoTqEm9QhyWf4KVSBR7jm+C53fan30irPXAwBe++ytrT2hA/TXMjsLixYQRmZyj3IKqhE/9dMzsmee2jKtK/c0bRMl11MLqkWJVEtGW8ZM7noLYNk2aeR/07Xr0u/YdfNz7jS2vM0/PIehjtaV+8bRMvZ98NUtndsprHK3sNAQcbMtI5OZrBhNyn1yvobji/UejnJ5IUcYU1umDeUuJof4Z7mfO6AtYjLZMoLc1evqvr9C7i21H9DTMuace/y4k9t/vVHKZqVgyd3CQkOecpe5LJJSH9yg3H//X+7Du//9wd4OdBnBDWmZoA3PnT5TmiDlfu6AVFCVcu5qFFK9jn5dgmybNNusA1B/x25C3r9+yVY8b8f6zHMaKncR5TxxyN3aMhYWGnLJ3RCFJE7PKvd6W570iQ76KOSWv34bdQZRSCXlLvVzBzTPvWBqP0BRyNZy7kDjBUV0bb0rJGMMf/O6C3OfYyqo0riB1m2Z5YBV7hYWGogwdHKWuV7OfQNZe8APo7bSJCc60pRL2kKgnfenK3e5nzugtR/wsu0HXMdsy+Tl3IHGREuRRX0npkbIy7kD1paxsDgpQJylE7as3GWyA7KKMoh4W8r2RIdsy8h3La2mhPTJkENV1p7UfmDNYAHvesXT8PLzN4nHhS3TIOfuOurq0cbtB8xpmEaQi72Z5zZI2awUrC1jYaEhL/kik30YqefqDkw9iOB3sGPRiQp5JyaZUP0wgus0b0OQLmKKf5b7uQOqLcMYw9tfuEN5fl5aRh6LJ/V/oWvlwZhjb0LM64aLWCe161Wu16AQu1Kw5G5hoSFPjerZduXrKW7LyHcoIecoeg7qQdTyKlU9Cgme3xXShLT9gDnnzlg8QcjXbOS565tahxFvqtw/8V8vzu3iKHLuJ5DnbsndwkJDHmGpyl21ZfQJ4ZQjd2kRUhhxDBXdmNxbfI8Rzyp3mQab2Rp5K1Rprih7LjyXKQmcZhtkEwpuTO5uk8Ywa3JUe3y9E8+WsZ67hYUGXR2ajoeacs9uycfbyoGf6EgTRPHXctLut9X3GIgNstMopCktk6d8ndyce3y9UsGB5zhKEbVhzt013DUsQXXLNYMTBZbcLSw06ERNUJQ7bTpBSlRjnXoYKasfu4179k9jamH5FknRJEbRQSL3VlepZmwsrStk3iYZhHQnJnMUsuy5cTte2ZZpqNzTx1YNFuA5cSG3U1D6ppebb7QLS+4WFhpylbuhcZgpCsk577kt88Zr71zWTpSC3EMi97Rveiugz4fO51DbDxRyNskg5O6hmnzEpUK80YbqueePR55E1g+XcMMfvgAvO39zS+/FBNFN8gRS7k09d8ZYGcBtAErJ+V/nnL+HMXYWgK8CWAvgXgBXc87rjLESgC8AeDaASQC/wTnf16PxW1h0HXkFVVPLX53k6fmco2dpGc45FuohKlLTq16D3rqu3FudwKJI/Zx4Ziemxis8aSLIW6H6gnM2oOA6YJJcbbjNnqPm4c9aP9TS+8hDu43DlgOtDKUG4MWc8wsBXATgFYyxSwH8NYCPcM7PBjAN4K3J+W8FMM05fyqAjyTnWVicNMizZciKcZjBc5dIJ9D86W5DV8HLgbzFQi2nZbQ7HM5VIiw08b3TRUxmcn/DL5yJv/ilp7eclnGctPjajYTLSem58xjzyY+F5B8H8GIAX0+OXwfgquT71yQ/I3n8JYydQO/YwqIJ8mwZIijPdZRNJwCV/Mi68KOoJzs0kVoO2+jKuFTopErKvd7i3QlNRLKCl/u5y5t1mCA269B3YkrGRUGXVnPuQGoBdYOd3BMw597STQRjzGWM3QdgDMANAJ4AcJxzHiSnHASwJfl+C4ADAJA8PgNgneGa1zDGdjLGdo6Pjy/tXVhYdBG5yj0hpoLDjAVCAtkx7azgbAd+kPX5ew19wksLqu2tUJX3UDX1c8/z3HP3UI248rjTYloGkPrBdIGQC07jyWkl0BK5c85DzvlFALYCeC6A80ynJV9N7y7zP4Bz/inO+SWc80s2bNjQ6ngtLDrGN392EJ+/Y2/T8/JsZCKoguekStSg3GU7phfWTF0o92W0ZbSXEuTeouee9paRPrecxmEm0HH9Toiu5xpUeDOiJd+9G7YMvX47+8r2Gm3Z/5zz4wBuBXApgNWMMSrIbgVwOPn+IIBtAJA8vgrAVDcGa2GxFHzzZ4fxtZ0Hm56XZ8sQkXiOk1mZKpOfXGTsRRySrr+cyl0n1XLiubc6eYWGgqpxD9UmOXf944w0cm9LuTexgtqB12T8K4Gm5M4Y28AYW518PwDgpQAeAXALgNclp70JwLeS769Pfkby+M38VN8a3uKkQD0IW1K7ebYMHaYVjfIx2f+WCb0XcUh/JRK6mf0AACAASURBVJR7ri2T//5+vHsCf/eDx+LnGwqqprRM3iLRvJx76rlnC5rNSNsTE0LD01rCydpb5jQA1zHGXMSTwdc4599hjD0M4KuMsfcD+BmAa5PzrwXwRcbYbsSK/fU9GLeFRduoBVFLi27ylDvBc5lQ6voOQ4BK6L0k9+VU7tm9Spvn3P/bZ+4EAPzRy85J92CVFLy5n7uZ3Zs1DiNSV2yZJjzrddGW8QyTy0qjKblzzh8A8CzD8T2I/Xf9eBXAf+nK6Cwsuoh6EC1JuRMKjpPJbcsTAhU89e+7hXpAE8rypWX0j6SdnPtsNRCTqhKFNLb8NV/DbZJzd4TnHkccOW+tPzvQXc/9pCuoWlicCqi12MWw2TmeYsuoi5mAOAJJ6KnnvoI5d7FCtcFnRbsiTS3U04Zh8qQo8WDTrpBNNutQdm0yJGdMSH3yhqe1BM91TihLBrDkbtFHaFW5yyo8b6PkNAKZfY68MrXV3ivtYCU897yceyPlPlqOe7VMLdQzbRryopDNc+5aFJKryl0+t9WcezdI2XOYJXcLi5VCLQhbUu76BhA6Cp4jRfoMyl2OQvbCllkBz10n1VILXSFXDcSu79RCXUQmQyktIy9i8pr1lmmyQlX2umnNZHNy724U8kTy2wFL7hZ9hJaVu0QgRUN8o+Cw1F6gLfmUbHuvbRl1QVA38cDB48ZVtXodYqCFnPvoQKzcpxfqmTscvf1AscWWv/o49Jx7fK76nDyYsvGd4sJtq3DZjsxazRWFJXeLvkGtxc0lZNIsGPbMdB2W6S0TJZtYRBHvfRQyIOXe+NpRxFteZAQADx+exa984g7c++R09lqZgmqSc28wwZAtM7lQzxRUM+0HvM52YtJz7vK5Tfbe6Oq+p7/6rK347Jufs+TrdBOW3C36Bq2nZdLvC4b4RkHqLSMvq9/xZ9/Dmz9/97JFIZu9l//z/Udw9bV3tXzd2aoPAJip+JnHMraM11y5U0F1erGeiUJqC1Sb+t9uXkGVZ20ZQe7NCqon4NZ43YQld4u+QBhxBMm/ZpCJrGCQf54r2TJkNyQkc9vj4z0n91Y99wNTFeybXGj5uvSe6oY6Qbag2jznTpPP5Hw9s4gp4no/92bKXb2mPma5oEqXbdavsJue+4kIS+4WfQHqXtiScpfOMXnunuM0bPkrF1FNRLlUBC167n4YYaEWNDxHBr0nU51APyTSMg2sIZrYphZqmTsdaO0Htq4ZwPZ1g3jqxmHjtdL8etZz14uwrTYES3PuDU87aWE3yLboC9SCeGOLIOJxUqOBWpOLdiblXvSYIDtuIvdoeWyZZjn3ehhhsd76hh70FkybjGSUu7BlWlDu0naAcsM1+TewerCIW//4RQ3H5zCWKaiGnGfik06raZkTsB9MN2GVu0VfQO473kzxyrbMcDmrfzzHEatDU1smfVwmx5X03OvJoq1We67T+zaNWSf3omg/kH9tsmDGZmvimIhCgrdNqi5jmTuIKOIZb73VtIzw3E9R6W7J3aIvUFMWFjUmRVkdXrRtNT7/lufgOdvXiGPyClUixEBR6+nzW1lF+uChGfzmZ+5EtcVt8+ph9jVNIJJerLdmzYQNyF2fSDyXoeAyfPzm3bj29r0Nrzc+X8sci6L2I4iOk7Vlwiir0FmLaRlXeO7tjeNkgSV3i75ArUPl7joMLzx3o9rkynHSPu48JStCvc2c+117p3D77gkcPl5pei7QeuMwmmQWWrRmUs/dVFBVf3YZEwXJGx4+arwejU/+vOXNOtrdoM1hLPO7C6MoQ+6tKvdCF6OQJyIsuVv0BchzB9pT7kQQSmzP0PI3L9veii1DRU9TBNEEkXNvclcglHuLRdWGtoz2mbkOExt0T0meugyTZZO3QXYrcBkzRiGz5N5uQdWSu4XFSYt2PHeZNE0qsOBm0zIy2ib3RFm3TO6teu7JeSblfvh4BR+54XHF5qDLmTx6vZDpSfn/qQXzuE3jo89W7wrZChgztR/IXqflgmoXV6ieiLDkbtEXqLXRzCtqptydbM5dRtWPxKTQyk5F7Sr31HNvXlAFzJ7773zpHnzspl14YnxeHCMCb6WgKhNnvEjJQOSGY/KK3nZJ1XWytkwU8Yy33mrOXWxqfYqyuyV3i75AO8pdftwx3LoXvMbKfbbiY7DoZV43D0Tus20r9xYLqrWscp+cj60UOeopFjFJ5H7oeAVBGGXI25Maw4QRx1w1O4EYlbvSFbJ9z13/vOOcu5M5D2hO2oUubrN3IsKSu0VfQCbZZl61zEmmv/uCw8B5TIamJlszFR8lz4HnsJZsmfl2Pfe2C6pZ4qUahNzfRaRlkoVXB6YWcfkHb8Ynbtmd2SBbtzwmF2rQEURR5vNTFjO1nZbJknvEOfTNm9JFTI2v183GYSciLLlb9AXaScsoyt2w8YOXsEbIeSZ3DcQkXXAdFFynRc89n9wPHa9kJpBmnvts1cdMxReFV9NCpkpyTF5wpdsyDx+ZBQDcd+C40Zb5yG9ciN++4ikAYmtGRxhycQcjjtGYO/DcPYdlJubQkHOnH1vNuVtbxsLiJEY9bCMto5B7/FX++yfFF0bcaMvMVHwUvDgH3ornPl8zF1QPTC3i+X99M+7cO6W+l6Cx5/6n33gA7/zqz4S9YiT3JOkiv1c9LXNwOo5mblk9YLBlGH71WVvxS888HUBq88jwI47Boqsck5V7u5RqmiyXkpbxmrQZPtlhyd2iL1Dz28i5ywVVzXNnTN04Is+WKbgOil6Lyl147qp9MjZXA+fAxLxqeTRT7gemKjg2W0vJ3RCFpKfKSlikZZLn7Z2Ii63DZS+3oLpmKOnZblLuEcdwyazcY8/dOPxcFD0ns24gDE3kro4xD3aFqoXFKQCZFJqlZcy2TPqzvFmziV9nKj6K7dgyOZ47rVjVryGTu2lyOV6pY6EWiAx+o0VMygIjWsSU2Dm7x2Jyr/lRxn6iz2DdUAmA2j+GEIQRBkuaclfSMu2RatF1MgXqkGfbGLS6h6ptHGZhcQqgY+Uu/vBTIhCbNUfmtMxiPZQ891ZsGTO5C19c6ywpk30YcSVzDgDHF32lU2Kj9gOy567bMrvHFsQ49M+EPoOBootywcG0gdzDiGOwoFKMvBNTu25I0XOU2gldL7/9QH/bMpbcLfoCqnLvpKAa/8wYE8QZRJFRuQPxIh/PZU3bD3DOhSeeUe5JokW/htK7JuLwJHFMsUSV3FtU7oLcOWYWfWEHLfoquevRw3VDJbNyj3hGuQcyubfpuhe9rHIPDOSe3mU1vl43N8g+EWFtGYu+QE1qytVJWoZJhEGqNczx3IG4+Fd0HWP7XGVc0u5Qes6dlLu+jF9X7jLoGvIERsr9mz87iNd84nZlzKrnnir3Q1Kfm0o9VF5HJ8M1QwWjcg8ijiEpLVNQ2jbw9j13g81V8UOxnyuhXVvmFBXultwt+gO1NloCmHLuMmGQ3xxF+RNFq547WTJrh4qYqwXK9arJxKBbO36Du5DjhjjlQpLGuWvvFO4/OKN48HL9IZI8d7mTY9UPFRtFJ/ey52buLniyp+yQpNyLyvaEndky+uvMVnyxETeh1YKqaBx2irK7JXeLvkA7nrtphaqcnabFMSE3F1SBmDhaiUJSMfW0VWUAqnqv1s22jNy1MYw4XvKhW/H+7zwMADhuSK2Qcj86UwUApftkoNgy8Vc/jDAxF5P7ltUDWKzHk06BluvrNkhO/hyAknMvSit7O+nnbiqozlZ8rNLJvcUUjGu32bOwOPnRqefOhC2TkrwjlLs55w7EhcaS5xpXh8qYF+Q+ACDdpBpIs+g6cfrKatsIT4wv4DNJT3WTcifP/UhC7vsm0n1VQ6Mtw4XffsbaQVT8CCFPC7eZbe1y2gIAUHLuhW4o9+S9f/6OvfjazgOYrQYYLevKvTVFbhuHWVicAlCUexM1LXdAJIKgv/9YuadRyDzP/eXnb8ZZG4awe2w+9xwgtUzWDxfjcUrE3SwKCaSETdB9+6LnCHI/Nhuf++TUonhctmWIeOtBhPG5GsoFB+uGi4ktw3MLkHILZP1aQyVNuStpmc4Lql+56wC+cteTmK8FWeXeoi3T6l6rJyssuVv0BTpPy9DXNDXjSgXVvEu98oLTcN5po5irBkpxUseC5LkDag+cSgvkvm9yQXns+KJK7qsHClioBaj6IaaTx/ZPyuRuSstEmJivYcNICYNFVxRUqcmYrtxNm2jQ3UbJSylGJff2V6jKnvtc1Rd3IKMDauiPtVhQLZzie6jaKKRFX6Dmh3BYbAc08tz1ZfbGRUwN2g+8/jnbcMU5G1D0HDz9tBEAwCNH5rB1zaDx9eY1cpc3FSHlbopCkp+/NyG49cPxYiKd3EcHChibrQrVDgD7JeWutB8QOzHFBdUNwyUMFj0s1gNEPO0g6Wq5etfJblxNdwRy18mi62A+it9vvEK1fc+d7mzmqgHmks+uc+WeeO5WuVtYnLyoh5Eo7jVaoaqTVFpQTb8qK1S1yeC3X7ADr3rGaQCAczePAgAeSRpwmaArd9WWMe+4VA8jlJP4H6nXDSMJuVfUguqqgQKqfiSKqQCwX1L7fk4UcmKujvXDJZQLLqp+hEjx3FXaiPusq++LJg15gVXJc5bUz53aOUQRx7xUy8jz3FvNuZ+i3N6c3Blj2xhjtzDGHmGMPcQYe2dyfC1j7AbG2K7k65rkOGOMfZwxtpsx9gBj7OJevwkLi2aoBxEGkuJeI+WuP6Y3DlNy7ob2A7JlMVzycOa6wYbkTn746sGYoGRyFytUE+b82s4DmJyvwZfIfW9isdCrzujKveyhLuXWGVNtmVDx3JG8Ho+V+0gJA4U45lgPIqHCdTJ0Gcv0lie7R/48ip6jLGLqNC2zUE9bKwAwRCFbS8t4p7gt04pyDwD8Eef8PACXAngHY+zpAP4UwE2c87MB3JT8DACvBHB28u8aAJ/s+qgtLNpEEHGUC474Pg+6zSIWMSFNVoicO8/aMnorgO3rhkR3RRNE4dGwuYe8QnV8roY/+foD+NZ9h+EHkVi4Q8qdrBs9LUPER+edtX5IeTww2DKVeojpxVi5DxTjz2yhnq56NSt3c0HVdcyee17KqBGKXrwxuW496baMyOPblr+NwTk/wjm/N/l+DsAjALYAeA2A65LTrgNwVfL9awB8gcf4KYDVjLHTuj5yC4s2EIQRSl77yl1W7PFX3XNXn68TX6lJZ0giV0qVmJR7EHLRmmCm4sMPuSB3Ok5e/fRiHSPltJRGxLd/ahGDRRdnrFW9/0DLzANxIZfz2OoZSCadhVqYeu56FNJA7vSeFeUuRSE76edeTIqzeqsDvaDa+gbZ8fVOUW5vz3NnjG0H8CwAdwLYxDk/AsQTAICNyWlbAByQnnYwOaZf6xrG2E7G2M7x8fH2R25h0QbCiIvkRkPlnnArEYm+RN1hLG0cZmg/UNCUu6kfijqu+DGyjOo5UUjKv89W/dhz1/qkU9RzbLaGM9elBE5+9PhcDcMlDyPJzy8/fxMAc1qGsH64KCaRhVog3pt+d2IqqKbKPT1Xzbl34Lknk8uk1gJZV+5pt8fWbJm+j0IyxoYBfAPA73PO801E8+ZZmb8mzvmnOOeXcM4v2bBhQ6vDsLDoCLEtkyj3BkqaSKqodQyUe8x4Qrln7QXPVf+kim52ybw+LiBd7KOmZaj9QCT2KB2bjYlttKyq1VoQFxrH5qo4c21qvZCqnZiPyf2xo/Gf7quTTTZkr1yfqNYOlQS514JIvDfT5hh6jZrelzzZKVFIdNbPHVA3BvEcZugtA+M4dXgtTgInK1oid8ZYATGx/zPn/N+Sw8fIbkm+jiXHDwLYJj19K4DD3RmuhUVnaFW5E/kQkWQLqkyQgakrpJ4Bb67c4wZaZS+r3CsiCskxlyj3A9NxMZSij4R6EGFqsQ4/5DjDoNwn5+sYLLn4/Zeeg/XDRbzgnFhQyWkZXX2vHSpoK0zNK1Q9h2USSLme+1L6uSe/kwlpv9ZVA4XMddKWv42v1/eNw1j8SV0L4BHO+Yelh64H8Kbk+zcB+JZ0/I1JauZSADNk31hYrBT8MBLkTitLTV44KXEiMr39gLyIydQ4TCe+Zs3DgojDcxyUkmKvaYVqEEZilyZaXbouiU4CwEjJQy0IRdxxu0TuZFlMLdYxVPTwqmechp1/fqXYIUlt+auObc1gUdzt0HuJPwNNuRuikKa0TMlzpI3FO2g/4KrKveCyTFImHh99babczXcipwpaUe6XA7gawIsZY/cl/14F4IMArmSM7QJwZfIzAHwPwB4AuwF8GsDvdn/YFhbtIVbuMVEFEcd7rn8IZ7/7+5mcuq7cXYnU469q4zDdytCJotmGHWHSj5yIK2+FKil3Soqsk5T7mqEiIp42BDtDsmWI3DmHsuUdDVNJy2ifxaqBgqgFAClRZz33rD1FbYrlz4PeY/y5ddbPHQCmkoLqtrWDOeTenud+qtoyTVeocs5vh9lHB4CXGM7nAN6xxHFZWHQVchQyjDi+eldc87/v4HFcfMYacV4ovGJavRgfl6OQauOw9DUKLstYBM1smSCMe7Z4rgPXYTkrVLnw3AnrhlPlvmaoiCenFoWq37Z2QDwmk9+gRO606YjcK163ZTzXUfzs1HNXNaHnOJme8yblTp9pGPGkKyTaAk0OE/M1uA7DW5633Xheyxtk9/siJguLbmJivpZJOywH5N4oQRjhF89eDwD4wYNHM+cBKZEwo3I3tx/QY5DxdeLdmPKah4VRJJbzyy1tgzASit8PIqVbJABskJV7sgCKyH3jSFlYUHIscljbFUlv+CUrd3qPrXjuDmOZ2kO6QlX13OmxTrtCArEtM1L2cPVl23H1Zdsz54n6SBPW3rJ6AFvXDOApG4bbG8hJAkvuFsuKd339AbzrGz9f9teNt6NzkuIfF1HCHz58TDlPpGU0W0ZuRkXKUG8cppOefJ08ayb23OPnlQpp75Sq3NY3ijLKfa3kua8ZjL8/MLWI9cNFFD0H5YKLgssUW0XeFSker2NcxASkFo7Jc8/m3LO1B7quYst4si3TQT93kXOvKZOWjlZb/q4bLuH2d70Y52waaWscJwssuVssC8bnapip+JherBs3lOg1gjCC5zCx4IZ6ossNtYBUvepRSOIJxlKvVm/5q3vRQEqIeUVV8tzpNUm5V6VtAX0pLQMA5YKjtNIlct8/tYiNI2VxTkGzVWRbBoiJV7Vl0seI3GWfnu5MMv3cHSdD7hSx1NsPAHHL5Yjne715UJR7Keu1E8RdVp+zm+0KabEsePuX7sFZ64cQRhzhCnicsXJnQrkT2WZ2EOKa506kjlS5K43DFHI32DJeWigdKmUeFmkZIFbuRO4VaSu8ehBhVlLuawaLCmmuHYqJ7uB0Bc/bsQ5ArLhrQaQob92WKbgst6BKpD5QdDFc8jAvLWIyKnfNdqI7FVNB1U+Iv+0oJNlqEW+s3E/xtgKtos/nNovlwtRCHdOLPoKIZ4pvzcA5V3YP6gRhlBYuw4infnZOPptIOeO5O1BWqMpvpWCwZZop9yCMFOVe05T7cMlDEEXKJhyrBgoKaa4eTHvBr04KqGXPRSHZx5VIebCYVe5qFFIid4k8NyYdJ/NWdLpJP3f5LkbuCkkcW0omGvrsO/XcAYiVtia0WlA91WHJ3WJZ4EcRwihCGPGMWm6Gr+08gBf+3a24e99Ux68fRByu44gFN7RqlHLXBOJ63V9W9lCVlDtvUbnXchIziufuuRK5x19Hyl5iywQi2756sKBYQGTLAGk6plxwhNIla2a4lPXc8xYxyeeuT8g933OPj8vOTJqWcfC5Nz8HLz1vE8rSXQzQWVdIMSYpLaQjnYgtuVtY9BxByGPVHvGMWm6GO/fEpC63qm3/9TXPXVLS8niI4EraCtW0OyQapGUMBdV2PHfPEVFIyriPlgvwgzjnvmVNHHFcPVBUkjmUlqHzgVglk2KnouqQTu6u2qqX55A79YpPu0JmbRl6L+n7Sj33F567EZ950yVScTmxZYyfSD5k5U5jMqHVnPupDkvuFssCP+Sx396BcqfWt5RTbxeURxeee6iSu6kzYt4KVaY1DlPSMoaCqvDc82wZidxLXragOlL2UAsjzNUCbFkdk/uaoYJCsDJpUy+ZOC2jKvchrdmY66ieu0zOz0+iokBqyzjJ5Kjn3OXPQ7wvg+dOE5JQ7m0qa5nc9fYLMliLaZlTHbag2ue4fdcE5msBXnHB5p6+ThBFiXKPmm5QrYMsCuq/0i5IjXsOg+tSWiZLREBKUPm9ZfIbh5ly7sJzD8zvOYzSHY6KniMijxWJ3IkMT0/IfdVAUdnqTiY9Uu5P2zwiio5UVM0o92SiE2PhwEXbVuPjr3+WshCKVHLNj5T3L18HMHeYlCc8+j7PomqG1pV78rXPpasl9z7Hb157JwBg3wdf3dPXCcK4kBqGHH6Dxl0mkFVhUsatQG5iRdluRbkruxGpaZm0fSySr1LOPYqUHYH0dr9Aq8o9Sct4LiaDOCaaKvfUcjlj7SAGCi62rBnI9GwhkOf+Z686TxzLtWX0nHvSxExuPAZAxCsnF+rKIi6CI9UgCH6UVe70+dBnvzTPvbktY5W7hcUywA+TYmoHaRlS7o022Wj22gAUz72ukHs2Dpgqd/LapSik5LmHERdtfU0FVSK0vBYEYRSJlE1J8tyJ3OWNKDaOlPDDP7gCm0bL4FIX7ZIUd9T3EwUkW8a4QlWd2EwJE1LJk/M1lLy0yRkhbaQmKffk8y1I8pkmzLSgmnmphpDJvRXl3u9pGUvuFgCSgmOzHqlLuX5C7K147vO1AD8/OIPLksy26I7YIbnLFgGlZYIwVqkRV4udZOFctG01LnvKOqFiZXtGpGV4bMsUXIZ6aCaTZgXVINQ891DNucvKfdVgAduSnZTkiU5V7tk/6YEcW0b33KOcVaOUTJlaqOMfr342nrJeXa5vsmXEClXZltE893aFtezRN0rLMBbHL9vN0Z9q6HNXyoIw1cNVo1EkFVOTf43wzXsP4g2f+SmenFzEJ299QvjP7RZiCXITKzktQ7lv+bp07ra1g/jKNZemSlhKYJA9FIRRUqiN/4wa2jK5yl313GlHpYoUhSTIOw7J84jJc5dBrRYGtU0tCo6TqTeYJiiyQCbm63jejvXYvKqsPG4qqIbSZy5ej+5iOrRlZOixThmuw/rekgGscrdIMDFXF95qt0FRQ6Hcm0Qh52shIg686xsP4Cd7JsXxZs/Lg+q5x2q1HkYYKLqYrwXKdcla0MlBLtIJck9y7mlDrQYF1Qae+6Dw3FPlbvLcZXKXVams3PUt54CY1MsFJ3NnZlrEVC6Yyf2ZW1fhnS852/geXIPnbuot4zX5LNpBI1XuMJtxByy5WySY6GGnRlKHROx+GJNi3h8oefJ6J8RGfdEbweS5+2EkFv+YUh66gpU9d/KR/TBCxNP2AZ0UVGnlLJ1Lyr3qh7G/LRH36kGzFSF70aZl+WdtGMJTN2Y7H3ouEzFTILaZTL8T12G4/v97vvG16XF6LwT6ncsTHr3PWoeLmFrFtrWD2LZmoPmJpzgsuVsAWB5yD5IVqoBqR+igpIWuNMMlKvfYc3eSnDsXXrQpCpnZbUh47nHO3WHx8yIek1u8t6qp5W9jW0bOuRc15V6WFiIB2Zw6gTGGouegkLRX0PG7L3wq3v6CHZnjnpNt+dtJIMlE7vS7kudI/S6mV87JGy/bjjcaWgH3Gyy59zmoKZS86XC3QbZMGKZ+e9zIy3x+IJIW6l9/M+U+V/UxUHAzBCdbBK4T91cPIy4igkpBNfk2E/fTIpGe68CPomQv0DRDr6O5co+U9gNhkiaq+CEGpIVIgFlVX3XR6clznYY+tFmRO5kFXJ0kTAS5c9WW0Tcv0ZNDnSj39191gSgqWzSGJfc+R8lzMF9bHuUeb1oRH/NDtWOhjLwcdLMI5Us//CP89hU78FvPP0s5nhb3HHguw0wltiJoIwrFluE0EZhfg8ZUSBYAxdlwltg1WbJKFzG1ptyB+HOq+JFo25uHPR94VdqUy3ONxdRG0De2zkvLNINZuWcnCj0K2Yly/81Lz2z/SX0KS+59DiLS8R6SO70G+clA4+QLKXTdc2+UsokijmOztUx/dvm1SLlTsVKQe6haE4DJllGVO/VCJ1vGzbFE2vHcyV+v+VHGljEJarloWPIcYwyyETy95W9OWqYZ8gqquk3lacq936OKvYaNQvY5iEgnemjLEIHIy84bNQ8jNSm3uZWvYwJdz0SidL1CknOnaCXdOZhWqGYKqpLnHl8rXt1JtozLmLGgmq7KNI89zrnHf4byRFD1QwwUU1tGb9ero+Q5HSl3XW13S7nLrYzT11ta4zCL9mCVe5+D/tBM+5pGEUc1CBsSy0ItyCyO0UF2irIqtIFyp8dmdHJvYMuI/uxGck8J23McQe4m5R42Kaimnntsy3CeJGg8R0mtEJoVVFXl7opzq34oerLLY83DW55/FjY1WLVpgu65R7yzCKGR3KX3RaCJrtaFnLtFc1jl3seIpAVFi9LOP4Rv/uwQLv/gzbnEdGSmggv/6oe4Z3/jPusm1dqKLbOgjalRQZU8bdN1Zc+94DlYqMXNuWjSMnWIlBcGAWkUkr56TlpQdRjwt697Jt58uer1A7HSLySbZJsQRDzdIDt5zaofxgXVYmrLNJtAr770TLzs/Paav8U7MWntBzrgW8dQUPXDKFMv0JuoWW7vLSy59zFka8RE4AenK5he9JUstIyx2RqCiOPJqcZ91k2Lj1qxZXQ06i3jG+4OxPUkz32o6IpJgtIySsMrSupoxCS6QiaHC4lypyLkS87bhLPWDxnHVnSd3IKqnJY5M0mBPHxkFpV6nJYhy2Ygp/i8FOiLmCLOO1LuNH65t8xiPczcbQjPPYz/P9l1Rr2FJfc+hqyEawYCpz/CPGJK+6A0TrG0t3pu+AAAIABJREFUr9zN12s0IdBYjK8lee6yxUTL8X0jueueO1O+eq6T5PabFwYLUn49O7a0iPmMLauwdqiIWx8bR9WPUCo4qCUWkt70qxvwHKZ8XnHOvfOCqlwToYKwjILeW8a67j2F9dz7GL7UnU9OshDojzDPDhGbOftmZU8weeWNlqA3Kj42e45pIpI9d5kkB4TnLt3B5Ch3fUcmIkbOeW5sklBwnYY7MZHydRyGK85ej9seH0fEuaLWaaOOboL2kxVj6TAK6RiUe8XPKnda/LWUKKRF67DKvY9BRDZc8owbKNQEuecodyL3etDwdUwpl0bJF5lsN4+WxdL5xgXV/LHS5iCe4yjKfcBQUCU/OEvuaiSx4DpJFLI5IcobX+uQ+7kDwAvO3YDJZDPxcsHFc89ai//1y0/H+666oOFrdAI95x5GnRVUPYPnvlgPxeernOum+7baKGRvYcm9j0HkPFIuoB5GivKSH6dJYM/4PH7lE7eLFIuwZZood2OCpQFRy8R/4bZVuPEPX4D1w8WGE4K4y2gwkejKnZSlbPf4SYQvLwoplHuSEY9y+rHIKHpO7t1IqKVKzt00Kr4fKLhgjOHNl5+lNBDrFlxtJ6aohbsQE2hCkH8/VDPQUXCY1Fum/deyaB2W3PsYvqTcgWwxsq4p9wcPz+KBgzN4Mtmomh43JW1kmOyUhpl1aRwUD9SJKO85ZlvG7LkT+egFVVNePfXc458LjiMahzUjqaLroG6oaXDOMys55e3tTMq3m/CSrD5tjB0u0XPXbRnT+AtealFZ4d5bWHLvY5CapE6CunVQE4SZtA8QSj5Ufq4289wNhdBWcu5Auik2RQ/zXyM/5y4vTJKbb1HBT1bVdUOED0gX3CjKXcq5N0LBY0blbup5PlIuiMmi5PX2z1OkXJKhdZqWMeXc85S75zhL6i1j0TosufcxiAgpQ60nZqjISoqe/ij146Tcd4/NGyOVJmJrRNSytUIETNHD3Oc0qA/I7WcHpbx4ulmHasuYFiPpnnvcOIy3odwbFHq1OwXaHKPXyp1ImT4z6pPT6XXCVpR7g8y/RXdhyb2PIQqqpNy1xExdK1KStVDTjlfqIeaqPl75sdvw7/cdUq7x490TeGJ8PvParRA1kKpXPdmR917qDRSy66rK3dQ4zA+4Wblrnnsh6S0TRvl96QkF1xyFNCl3IN0ftBfZdnVcKimHnfaWMRRUc5W7y6xyXyY0JXfG2GcZY2OMsQelY2sZYzcwxnYlX9ckxxlj7OOMsd2MsQcYYxf3cvAWSwOR6EjJbMsQmesLhIQ9I0UhZ6sB/JBjekHtUfOHX7sf/3DLE5nXblxQTR8j5R5HD5vHJ03XJfIuOKx5WiaMUPCypCP3cwdUW6aZT130zFHIdHGV+mdIyl1fJdtt0OvS5xNFnRGurtz9MIp3mDIpd8d67suFVv73fB7AK7RjfwrgJs752QBuSn4GgFcCODv5dw2AT3ZnmBa9ABHicJ4tE+jKXbNnglS502IbfYJYrAdG1WpKtRBUzz0hd62DYfa9NLBlkslCT8uUPAeMqZNJvudusmWSgmqTv6J8WyY+pit3Ive5auOI6VIhNrZOPrOww7SM3hWSbDpTS+eCaz335ULTXyXn/DYAevOQ1wC4Lvn+OgBXSce/wGP8FMBqxthp3RqsRXfh67ZMRrk3JnU5LVOVtodTrpG3MrORCpfIVtgyTv5CIPm9NFoNq+fci66TKElVuZs8d7Mtw1vLuXvmnHteB8pnbl0FoHmzsKXC02yZiHeYltGUe9pSObtG0pM8d0vtvUWnK1Q3cc6PAADn/AhjbGNyfAuAA9J5B5NjR/QLMMauQazuccYZZ3Q4DIulQF7EBGT7y6TpmKRlr67gpS3hqP+MTGKc8/zFOy2mZUqSLdPQc9fGJEPx3KXtnwquk9grckHV7LmbCqrUz72Z517yGhdUdeV+9aVnYuuaAbz4aRszz+kmhHJP4pC8hfdigitSN6pyHyhmP0dPUu52EVNv0W1Tz/TbMv5Fcs4/xTm/hHN+yYYNG7o8DItWoOfcM1FIsmX0lEyg9pyp+KFQa7K1E5NGzms3SsvItowoqDbLuTf33D2Hoey5aVbdc5JVmq3k3OlrotxdBj8hxWY1yJLnGnv3pHu7aqthnbgRWa/JT94ZKe8uohW40iQBxDYdYC4IFxxJuVtu7yk6JfdjZLckX8eS4wcBbJPO2wrgcOfDs+glSEGlaZnQ+LheUK1pKnmxHgrilxM3ea2CgSbKXbZlRBSycc69sS2TetuOw0TDsILLRAMwecyNlDsRUrzRdtRSP5ZywWzL5Cn35QKR72I9lLYX7KC3jLaIiVYsD+TZMtZzXxZ0Su7XA3hT8v2bAHxLOv7GJDVzKYAZsm8sTjw0U+7ZKGR+WqZqKKg2IveG/rn0PKHcW1yhWg8jjM/VhHoE1PYDAETWveA4mev6YWRMqRjbD4Q8SZjkDgtAPEGZGrOFUqF3JUBpoYofgOa3TgjX0zz3hspdaqJmqb23aCUK+RUAPwFwLmPsIGPsrQA+COBKxtguAFcmPwPA9wDsAbAbwKcB/G5PRm3RFZCXnrdCVffcdV9bJnnaWEO2H/L8dqDZlnnZtIzrOI17y0gT0a//00/w8Zt3icdoiT/ZHENFV6j4gqsXVPNy7prn7jBps47mnnstCMUyf8JKK3cqeFbqUdONwRtB7y2j73QlQ/68m6WMLJaGpgVVzvl/zXnoJYZzOYB3LHVQFssDkXNPmlJlo5Bazl1Ly9Qk9X18sa48Jp9vQsOcu9JbJmaAglb4zL6XmDA4Bw4drygbZetbvg0WPUHgnrYbUa7nnnxNlXu8qKqV9gMlz0HE43HI15Y3EVkJEPku1gNRDF1Kzj0tqMYRTlMUUv492H7uvYWdO/sYmcZhEhlHEc/0SNcVu2yfTBO5y557mN9zJq9LYpR0WiSkOffGyl22eWgPUkIQRgqpDJXS7etcraCal3NPPfc0CumHPPbcm/wVUfMzPSaaFlRX2pYJhV++FFuGPsdqE+VOsJZ7b2HJvY+R7S2jLubRz8vk3EOZ3OM2wPKWfFWDz0zI20qPiqZEDKK3jNZ7PO+9mF5b3u0ovnaq3AtJYVS+TuOce/yVEi5BGDWPQibNz3SbKq0FrMyfYarcwyWlZTIF1QaeuzyR2Shkb2HJvY9BXjr1W5FVt0r0qudOdo2s9I8blXv7nnugrZolW6Z5y1/1MbmgGkZciRvGyt0csczrLZPZiYn2Aw2ilmwZIEvueb1llguDhfgzltMyS+sKGf+8KNIy5q6QBNvPvbew5N7HIJXquXFqRPbcZeImVZxZxCSdM7VAnrv5GjryiJpea/VgXAcYLKW2TJ6VIz+PIG8gonvuT904Ijazpu6O8nVMvWX0gqrYDzSMWsq5A9moaXCipGXqaVqmkxWqNHxK/1TrIRgztywuSp+t9dx7C7uHap9i99g8dh2bF95zSVsi38iWkfPv5YKDqh/heGLLtFJQZSy/oEoEftWztuCsdUPYOFIGkBRU27Jl8j33P7zyHPE9dXeUr9OonzvTlHvNb67cyzm2zEor92KyiGuxHkoF1favw1i8c1UorVClXaR0WOW+fLDKvU/xx1+/Hzc+cgyFRF2VCuoqSlllZlr+St776oEiAFm5m60dGSXPyW0cRgS+ZrCIVz4jbUvkOY7YC9UE3QKSlXsY8UzPdIJeUPVD3qSfe5qWAeK7mea2TKLccz33lWO5gaKreO6d2DJArPjpV2DaHJugFI8tufcUltz7FIePVwCk6QW9/0ldSZ9w5Zicdyf7RCh332zLkHqNv3dzlXva5Ev9y/dc1nLLAgCZRUxeTtGSNrpOr5Oj3LWCasGRPffcYQGQPHc9LSM1NFspDBZdVCTl3oktA8QTFNkylXpojEECalrGrlDtLawt04eIIo6J+VhpE7HpnQtNnjsdm68F+OStT2ChFmDzhuH4Ma01QXwsJbNywRUJlrLnNvXcdYLNW6FaDyK85v/egT3ahiC6cs+zPuRWwlHEkyx6A+XuqMpdfiwPzdMyK0dyg0UPi/7S0jL0PJojZ6sBRnM29FZz7ha9hCX3PsT0Yl38MVOEseQ5uX1hfI24f35oBj8/NAMAeN6O9cq1a0EEzjk+8L1HxAQCxLG444hfq1xoZMuYs9/yZs6ylzs+X8MjR2Yz16n5EXaPzWO45CGIolzS8qSWv3RnYCqoEhOJpmPS+E7WnDsQ/14q8iKmDsndYekiptmqL1Y961AmRWu69xSW3PsQY3O1zDG9c2GtgXKXMVzyMFR0RfsBIM6Yf/o/9yoESLfpjMV3CfkF1XzlDlCsMb3u5Hz2vQDxncTbv3QPzjttFEHIcwnUk+wEIvmWPHeJ0Vtp+QuYlPvKpmWA2JaJC6rxz50ORW7ANlvxsW3toPG8omuV+3LBeu59iHEjuZttGcayOXcZRc/BmqGicmwiIVzZBy9JDcA8bYOMqYU6Hjs6pzxHbwFA5Kzn4yeluwOdY5+cWsTh45VkEZP5v7qcc6cVtw3TMtp4gBYah+UUVFc6LQNkC6qdeu6OVFCda2TLuK1PihZLgyX3EwR/+4NH8d5vP7wsr2Ukd60tLX0/XPTgB5Hwo3UUPQdrNXIfN6jptAEYy8Qa/+8tu3H1tXcCkNvzqv81KVeuRx4npNca1Ip4tSDC+HwNYcRFAVSH3Eo4764ByCp3efJpRoip557e3Tx4aAZfv+dg/PwVVu6VbqRlnHSFakNbRvbcLbf3FNaWOUHw4ycme75nJiHPlpmtpK9PRDRU8uCHUe5q06LrYM2gRu6G61NaxnOczGrTifkaxudrSj+brOeeKHetqDopbcg9UPQUewgAJuZqOG1VuYHnno6lLsg9e266QTY9r3UFWvbUFcC3PT6ON372LmkMK5mW8bDoB0tOy3hJ184o4pivBRgdMCt3m5ZZPlhyP0EwW/FFVrzXGJ+rYajo4sY/eoHYKanoOsbVpUMlF34Y5WbWZeVedB3Uw0hR00SUsnL3XHU/1PlqAM6BuVogFH2e5561ZdLXGiq5mFBDM1ioh5itBFgzlGcTsLSgSp67YWUl+TF6+wH5WB70tMz3H1S3OFjpnHtlib1lgLioHHGOuVr8uxzNLahaz325YG2ZEwSz1QDTi37DTSy6hbG5KjaOlnHaqgGcvnoAQKysFyXVK/ZXLRdQD3m6a1NJ/aOVlTupNVm5lzwXAwVXqFdP2DIpSc/V4juGmUW/Qc49adSlZd1lz920ITMAPH5sDpuSla46PMdBGEV45Mgs3v3NnwNoZssgc04zPqQCLU2eR2aq2LFhSBrDCtoyBVdZodqpmI4/R465apyIyvPc5f8/Vrn3Fn1J7lWpxWk3MTZbxSs+ehuenFxs+7mzlfiPwqTej8xU8K37Di15fITxuRo2DJeUY+uGS5icr4sNJchCGE6Uu76ZNiFW7kkfmGRVokzuRc/BQNFFwYvtGNdhGCp6mJcsKPp+puI3TcvMa9bVhPR5yQulZAQRx1MkMlWumxRUr7//MH78xKTxtQGpnzvl3CVCbuZTOw5L7ozi93bkeBVPSdYHAMhdPbscGCi6qPihKIZ2rNwZcP39h/FHX7sfADA6YJ5oSUwA1nPvNfqO3KOI4xf/5hZ86c79Xb/2g4dn8OjROdz75HRbz6v6ofjDN/nVX7nrAN751ftE58WlYmK+hvUjqk++caSEih9iPlHRROZDxcRzFxt7ZMmd0jKk/mRbpug6uPyp6/GsbatjS8ZhWD9SUs6h15yp+Lk5dyLcKz9yGx5MMvaAass06hp51vph43EqqMoTstFzT0gv3SC7vb7kJc8ROffDMxWctiq9k+jU5+4GBoouOE832FjKClUAuHPvFIB85b7Fkvuyoe/I/XjFx/hcDfcdON71a4/NxkRzVNoFqBXIhdQJQ9KEjj0xvrCE0aWYWqhnEi4bR2MlT8XW6UQRD5fitIy+mTaB83QnJ7obGtOU+4d//SL81vPPgucwuC7D+uESpqSFVETuxyt1odz1IqOsKCk2CcS2DHnkNEaT+sxT7uWCi1oQYddYek1jP/fkK11afo1W7AVKI83XAsxVA5y2agDfesfleMMvnJHbh2U5QAmjhVo88XS+iEl93kgOuW8aTSc12xWyt+g7cield2CqfeukGUh1H51pj9xnE58SUD3k9BiRe1otfGJ8Hn/8r/djodY4YbN7bF6oMiDOVh+v+Fg7pNoy5Ekfm63i4PQivvjT/XjRuRtQLrqoS8pdt2Xma74gCOoKqHru6X8xN8m4rx8ugvPUglJtGfNCIllNH5uLP1/OOSYXanhK0r6XJgY9vQNAtPjV8bTNI+AcePxY+tkWjBtkdx6FBOLaw9hsFXfuia2f01aVceG21fjfv/qMFc17U51iciH+nZnuWlrBtHZXmWfLKJNi37HP8qLvPl5aEr+/A188D0QqlO9um9wrKbmblDuR4BPj8zi+WMff37QLL/nQj/Cv9xzEnXsnc4uwfhjhl//+dvzTj/aIY8cX6+AcWDuoKitS7uNzNXzxJ/sRhBzvu+qCOAETRKJPjO5Hz1cDoTxpGIotIxGll3ju6xO/f2K+hloQCgtopuKnOXc9CikxwbHk8z06W4UfcuzYqPa3WSfdlawaKGDL6oHcRlbP2LIqc6yVxmFqFNJ4aQUlz8GNj4zhrdftBADFlllJUOO3b9x7CEXXwdM2j3Z0nWOz6v/bPFtGhlXuvUXfkTsplLG5mtI5sFPctXcKF7znBzgyUxG2zJE2bZkZidz/+c4n8YWf7FMepyz3E2ML+M4DR/ChGx4XpPlv9x7C0//yP/Do0Wx/laMzVVT8UHmMJoq1WkF1Q6Lcx2ZreGJ8HmetH8LWNYMoJFFBqgmQJ751Teydbhgt4+mnx4TwjhftAKBucVdUlHvcP1wmd7lAOrPoi54zOrnLdzdEJB/43qMoug5+7VlbAKS2DMUeh0setq0dwNmbzH47vY9VWibbnHNXPXd5fLKPnIeSNrmc3sJzlgOXP3U9Bosu7j9wHM89a63YcnGp0O07GbT9nm0t01v0Dbkv1AJMLdQV2+PA9NLV+30HplEL4igdKffHjs7i1/7hDmNDKxNmJYJ7cmoRf/mth5THiZD3jM/j8PEKPIfh0fe+AtvWDuA7DxyBH3I8fDj7WgenK8nzFjLXWqd57qNlD+WCg2OzVeybXMT29XFvkEKSSSdypz4sr3v2Vnzxrc/FG557BlYPFrHvg6/GLz3z9MwYSgblvm44fu3J+brw2wFVuRe0e/bNktI9NlfFQ4dn8O37D+N3X7QDF5+xBkDcCZIxYF1iOY2WPXz0Ny7C+15zQWZcBMYYLtiiqlVzbxn6mi2oXmBQ/zr07DzdKa00hkoeXnHBZgDAC8/dsPTrFV0MFl3j3Q/htNXx77LRhucWS0dfkPvkfA2XvP9GXPy+G/C5O/aK492wZuga+ycXMZZ4wVU/wr1PHscduydauoZsyxAoWRGE8S5HBZdh/9Qi9k8tYtNoGY7DcJ50C33EYAUdnE7HRsVLInfdl2aMYeNIGUdnq3hychHb18UeddGLVx7+xb8/CCDthzJYdPGLZ29QCnAlKYpIqZqilypWz2UZ5S4Xk2NyNyv35+1Yj7vf/VL82sVbcGymim/cE9sIb37edpGv//9fdi4KroPRgQIYi3P3T904ktvEinDh1tWKF2yOQqo5dzkKec6mkYbXB9IC9caREp6xZZXoN3Mi4OpLz8Sm0RJefv7mJV/rzHVDTS2Zy5NOopSusugNTmpy55xj78QCdu6bwq/9wx2CXP0wwr/c/aQgyLv2Ton+3vsmF4WKerILRVW6xv7JRYzP1ZSC496J1tItZDk8/bQsWU8lhapnbFmFMOK4c88UTk+Uz3nK+bFKl/33Q8mGHPUwwpd+uh/7JhaExUPqWcbGkRLuP3gc9TDC9qQASURHdwG/9+Kz8aJzN+DXL9mWef5w0cP65LpkVcgqmJT7aNlD0XXwkycmcdMjY+Lx44u+uPsxEeyGkRI2jZZxeKaKf7/vEF5y3kasHizCdRj2ffDVeNPztmPjSAlbVpcxUHBzl8Dr+O0rduArb7tU3GWYC6rxV30nJiBnRasGukv82OufhW//3vNbGtdy4VlnrMGdf/bSppNgI7zvqgvwZ696Gs4/fVRYdnn4y19+Or7wW8/F+ac3v+Ox6BwnNbl//KbdeOXHbsPf/uAx3PvkcfxV0njrhw8dw7u+8XN86IePAQDu3jeNkufgwq3xf6bt6waxaqCA3WPqWvV/3XkA331AXRqu47Gjc/jwDx/D/skFfOB7jwjL4+Ejs6j6EZ62OVVx+yZbJPdKgKLr4F9/5zJ8+o2XAAC+ee9BfPb2vUJpP+estQBitXvaqviPh+wAh8ULY8bmqjj/PT/Ax27cBQA4lBAyALzn+ofw/u8+LBTk6sEs8W0aLePAVPwcUu7TQukXsGawgAtOX4XPveW5WG1IpDgOw69cGPvfVGQ1pWUYi62Zmx4dw0dufBxAPLH8ZM8krr19L1563qbcAujmJEo3tVDHay/emnn8O7/3fLztiqfE5N5CUQ8AVg0W8Nyz1gqryrTAjcjd1M+9FZBIferGfP//ZMbVl56Ja67Ygb96zfn47Fue0/DcguvginOWbgFZNMZJTe6/ctHp8EOOO/dOYfNoGd994Ai++NP9+PETsR1y7e178ciRWezcP4WLtq3G0xOlsG6ohPNPH8VDh2fAebwBRC0I8d5vP4z3XP8QgjDCo0dnRWxNxpfv3I+P37wbf/0fj+JTt+0R6njnvnjxxrPPXCPO3Teh3hnc8ugYfrpnUqwCJcxWfYwOeBgqeTjvtHhy+PtbduMD33tEFA+fc+ZacT4lLV78tI341NXPxgvP3YgjM1Xs3DeNehDhIzc+jtt3TeDgdAXb16Vq7LZdEzgwvYiRkme0BeSxk+dOhb+vXnMZ7v2LK7HKMCnI+LWLY3KvJEVV1XN3hP2h20hkE21fN4iPvv6i3OtvkrzqFz1tY+bx1YNFlDwXm0bL2La2vaLlP179bLzi/M3GJIteUB0ouPjVZ23Bl9/2C229xnrDHdOphMGi1/KkatFbnNSNw85aP4TXXrwFX9t5EP909bPxsZt24T3fehCjAwVccuYaPHxkFh+98XE8dHgWb3/BDvGHtW64iC2rB/C5O/bh5R+9DRU/xAvO2YC5WoC5WoD/3D2Bv79pFx46PIsf/P4VwqIAIHYg+v6DR8WxNYMFsaPRC87ZgDc+bzu+dvcBfPzmXaj68X6SMxUfb73ubkQ8HvcHfvUZuGzHOgCx505/EJtHy8mWZRwB57gnmTTOWDeIzaOxJ07k4zoMLzt/M370+Dh+9uS0WJi1YaSET/5oNw4dr+DCbavhuQ7WDhZx174p/Nu9h3KTGldfdibe+5347ody72+87Ey8+pmnKYtPGuH800fx568+D7949ga8/KO3aWkZJrz00bKnFJJp0vib112YydLLoFTPb1yyreFS+S+/7Rfa9rWfuXU1/vHqZxsf06OQjDF85DfyJyEdX/+dy3DoeMX2MLdYNpzUyh0A3v3qp+PTb7wEF25bjY+9/iJsGi3j+KKPV1ywGa+9eCt+8NCx/9feuQdHVV9x/HPyJJCQJSQBTIgkKAjK00BpeYjKe0pRh3Zix+r4gGmVDtWpM6i12ulUbWtfVlur1BmVCloLreNALSoMlpFHBCQgIhFBUsNDhIgij2RP/7i/rLvJ7iaGhM1dzmdm5977u/fuPd97ds/+fuf3299FgKkX92aAS5nkZ2dySVEupxqCvHfgM06eDrJo3YdkZ6YR6JrOwjd2s3nfUU7WB5n//JbQuO2GoPKOGwETXvlurPHmdEnj0n49KApkUZrfDVUY+9Dr3L2sitd2HCCoMGd8Kafqgzy4YgfgDd/bX3eCHJcfTktNCaUeAN50rYe8bhn0L/R+ZHrnRgbn8wJZHDl+mnW7DzOiJMCNY/uxtvow+44cp7hHFitvn8DiuWMoyMmkPqj0iFH7Tk9N4c27rmDxnDERzwptbWAHL+jdMr6Mgb1zyEpPjQjuPbMzQqmPf942NpSCAvj17KE8d8vXIloP0RhZEuDx60by86tij4ABrwaf1Y7//CzJ68qkQYUMKw606fzyfnnMGl7UbvYYRkv4PrjnZqUzeXAvwPvL84PXDCEnM43LLyrkxrFeB9sD1wxhSHEuA3vlIOLVbBvz1d0yUnn5h+MYURLgO+V9qRhVwtrqw6jC9y/rz7u1n3L1n9aydFMN85ds5sTpYKiTcOYwb+jf9V/vR1qK8JfvXRqqLZ7v0iGHPz/FCxv3sWBpFakpwu2TB3DTuFK21tSx68Ax5j5bSeXeIxGzBBaFdUht3HOEFPHSFv3dZFONHaqNNNbkt9bUMbxvgIpRJeRnZzC0OMC1o0oQ8Toy75w6EKBZX0Pke2WFWhRnyn0zB0d0vD567ZdBuawgm0mDvkyrlOR15RsX5Dd7j6aICNMu6dOqTsz2pGtGGgtvGHVGnY6GcTbxdVomGhMHFrL1/imh5u/6u68MrffMzuTpG0cztDiX7l3Syc/OZNKgQgq7d2HZrWNRVY4eP82idXtJT/WC4ZSLe/HdJ9dxh5vtDmB2eTEvVtZw38zB/PHaEQDs+sX0iCb3Rb27M+6CfOZMKOPf2/azeMOHDCvOpWtGGt8adh4PLN/Bo6uqWb3zEHPGl7Jg+qDQuQN6ZbO/7gRBVWqOfMHEgYWkpgiXFOWSkZpC3x6RASZ8DPiYsp7kdcug8ieTm92bb19azKa9Rxjet221z69KxeiSiO2m+frw+2XpCsNoX6Rp514iKC8v18rKyrN+3f11J8jNSm/WfF9RVcuphmCoGb22+mM2fPAJtXVf8N9dH7Pqzokc/PRkq2txO/cfY+rv13DzuFLu/eZgAOY9t4mX3ch4uLJUAAAFvElEQVScV++4LGIUxecn6zl+qoHLH17NZyfreeam0UwYUEBDUPno6BfNrnvidAMPv7KTESU9mDGkt68C5fwlm3lj18dsurf5j5FhGPERkbdUtTzqvnM5uLeFYFDbNHPe6+8eYEhRgIIcb7RH9cFjTPndGsoKsnn1jsuinrO8qpblVbU8UjGizbP1GYaRvJz14C4i04A/AKnAQlV9KN7xfgru7cmidXs5L9CFKy7qlWhTDMPwIfGCe7vn3EUkFXgMmAzUABtF5CVVfae9r+V3rhtzfqJNMAwjSemIIQejgWpV3a2qp4AlwKwOuI5hGIYRg44I7kXAvrDtGlcWgYjMFZFKEak8dOhQB5hhGIZx7tIRwT1az1+zxL6qPqGq5apaXlBg80wYhmG0Jx0R3GuA8CkDi4GPOuA6hmEYRgw6IrhvBC4UkVIRyQAqgJc64DqGYRhGDNp9tIyq1ovIPOAVvKGQT6nq9hZOMwzDMNqRDpl+QFWXA8s74r0NwzCMlvH9xGGGYRhGczrF9AMicgjY28bT84HWPazUH5iezk0y6UkmLXBu6jlfVaMON+wUwf1MEJHKWH+/9SOmp3OTTHqSSQuYnqZYWsYwDCMJseBuGIaRhCRDcH8i0Qa0M6anc5NMepJJC5ieCHyfczcMwzCakww1d8MwDKMJFtwNwzCSEF8HdxGZJiI7RaRaRBYk2p62ICJ7RKRKRLaISKUryxORlSKyyy17JNrOWIjIUyJyUES2hZVFtV88HnH+2ioiIxNneXNiaLlfRP7n/LNFRGaE7bvLadkpIlMTY3VsRKSviKwSkR0isl1E5rty3/knjhZf+kdEuojIBhF52+n5mSsvFZH1zjfPu/m5EJFMt13t9vdr8SKq6ssX3rw17wNlQAbwNjA40Xa1QcceIL9J2a+ABW59AfDLRNsZx/4JwEhgW0v2AzOAFXjTQo8B1ifa/lZouR/4cZRjB7vPXCZQ6j6LqYnW0MTGPsBIt54DvOfs9p1/4mjxpX/cPc526+nAenfPXwAqXPnjwA/c+q3A4269Ani+pWv4ueaezE98mgU87dafBq5KoC1xUdU1wCdNimPZPwt4Rj3WAQER6XN2LG2ZGFpiMQtYoqonVfUDoBrvM9lpUNVaVd3k1o8BO/AenOM7/8TREotO7R93jz9zm+nupcAVwIuuvKlvGn32InCliER7dkYIPwf3Vj3xyQco8B8ReUtE5rqyXqpaC96HGihMmHVtI5b9fvXZPJemeCosReYrLa4ZPwKvhuhr/zTRAj71j4ikisgW4CCwEq91cVRV690h4TaH9Lj9dUDPeO/v5+Deqic++YCxqjoSmA7cJiITEm1QB+JHn/0Z6A8MB2qB37hy32gRkWzgH8CPVPXTeIdGKetUmqJo8a1/VLVBVYfjPdBoNDAo2mFu+ZX1+Dm4J8UTn1T1I7c8CCzDc/KBxuawWx5MnIVtIpb9vvOZqh5wX8Ig8CRfNu19oUVE0vGC4d9Udakr9qV/omnxu38AVPUosBov5x4Qkcap2MNtDulx+3NpIYXo5+Du+yc+iUg3EclpXAemANvwdNzgDrsB+FdiLGwzsex/CbjejcoYA9Q1pgc6K01yzlfj+Qc8LRVuFEMpcCGw4WzbFw+Xk/0rsENVfxu2y3f+iaXFr/4RkQIRCbj1LGASXj/CKmC2O6ypbxp9Nht4XV3vakwS3Wt8hj3OM/B6zd8H7km0PW2wvwyvR/9tYHujBrxc2mvALrfMS7StcTQsxmsOn8arXdwcy368puVjzl9VQHmi7W+FlmedrVvdF6xP2PH3OC07gemJtj+KnnF4TfetwBb3muFH/8TR4kv/AEOBzc7ubcBPXXkZ3o9QNfB3INOVd3Hb1W5/WUvXsOkHDMMwkhA/p2UMwzCMGFhwNwzDSEIsuBuGYSQhFtwNwzCSEAvuhmEYSYgFd8MwjCTEgrthGEYS8n++QzchbN4mdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# learning process\n",
    "frames = []\n",
    "qTable= np.zeros((1,1,6,12)+(env.action_space.n,))\n",
    "j = 0\n",
    "scores=[]\n",
    "for i in range(epochs):\n",
    "    done=False\n",
    "    state = calculate_state(env.reset()) \n",
    "\n",
    "    alpha = get_alpha(i)\n",
    "    epsilon = get_epsilon(i)\n",
    "    j = 0\n",
    "\n",
    "    for t in range(500):\n",
    " #       env.render()           # uncomment to show learning process via the rendering,  is very slow\n",
    "        if np.random.random() <= epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(qTable[state])\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        next_state=calculate_state(observation)\n",
    "\n",
    "        old_q = qTable[state][action]\n",
    "        next_max = np.max(qTable[next_state])\n",
    "        qTable[state][action] =  (1. - alpha) * old_q + alpha * (reward + lr * next_max)\n",
    "        state=next_state\n",
    "        j+=1\n",
    "        \n",
    "        if done:\n",
    "            frames.append(t)\n",
    "            print(f\"Episode finished after {t} timesteps.\")\n",
    "            scores.append(i)\n",
    "            mean_score = np.mean(scores)\n",
    "            print(f\"Mean is: {mean_score}\")\n",
    "            break\n",
    "plot(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated the state depending on theta and theta_dot  (x and v is ignored)\n",
    "# uses 6 and 12 buckets for theta and theta_dot --> 6*12 different states\n",
    "def calculate_state(observation):\n",
    "    # position, vertical speed, angle, angular accelaration\n",
    "    x, v, theta, dot=observation\n",
    "    \n",
    "    scale_t = (theta + abs(env.observation_space.low[2])) / (env.observation_space.high[2]-env.observation_space.low[2])\n",
    "    t_state = min(5,max(0,int(round(5*scale_t))))\n",
    "    \n",
    "    scale_dot = (dot + abs(-math.radians(50))) / (math.radians(50)-(-math.radians(50)))\n",
    "    dot_state = min(11,max(0, int(round(11*scale_dot))))\n",
    "    \n",
    "    return tuple([0,0,t_state,dot_state])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of Performance of the Learning Process:\n",
    "![sceenshot of Plot](Screenshot_CartPole_Outcome.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ]],\n",
       "\n",
       "         [[  32.5656939 ,   36.96828736],\n",
       "          [  14.64762614,   33.24091845],\n",
       "          [  10.33224392,   33.09199186],\n",
       "          [   0.        ,   24.53940894],\n",
       "          [   5.96978964,   30.13069738],\n",
       "          [  17.72774174,    0.        ],\n",
       "          [   0.        ,   21.0159019 ],\n",
       "          [  57.34958998,   59.57225384],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ]],\n",
       "\n",
       "         [[3633.91416019, 1639.63575199],\n",
       "          [3844.84806784, 3141.68235566],\n",
       "          [3800.3597935 , 2776.67367757],\n",
       "          [3860.84435544, 3795.96367213],\n",
       "          [3852.69542322, 3489.45896253],\n",
       "          [3865.27563945, 3852.19844167],\n",
       "          [3865.33120959, 3843.39258186],\n",
       "          [3820.88930253, 3864.28274692],\n",
       "          [3815.70912868, 3865.50666187],\n",
       "          [2865.80142961, 3784.77218926],\n",
       "          [2115.52551461, 3813.34488122],\n",
       "          [ 241.25386742, 2002.15487432]],\n",
       "\n",
       "         [[1440.81108082,  384.65217619],\n",
       "          [3827.84564083, 2153.16641783],\n",
       "          [3747.79152066, 2837.14946889],\n",
       "          [3864.69166333, 3816.75377902],\n",
       "          [3866.92431861, 3802.11657012],\n",
       "          [3847.34700634, 3864.26646654],\n",
       "          [3846.0209743 , 3866.47959579],\n",
       "          [3479.11294979, 3855.68067393],\n",
       "          [3803.24496149, 3864.16739578],\n",
       "          [2586.52972252, 3783.53578618],\n",
       "          [3230.72730273, 3847.02650896],\n",
       "          [ 568.41155066, 3600.66820536]],\n",
       "\n",
       "         [[   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   4.72635215,    0.        ],\n",
       "          [  59.55304794,    0.        ],\n",
       "          [ 163.03963103,   51.76346485],\n",
       "          [  32.58543191,    6.53734648],\n",
       "          [  44.52738305,    7.52945631],\n",
       "          [  47.25244724,   13.82186085],\n",
       "          [  50.06751886,   22.64474771],\n",
       "          [  23.17208332,   47.21390673],\n",
       "          [  52.09746185,   40.58286307]],\n",
       "\n",
       "         [[   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ],\n",
       "          [   0.        ,    0.        ]]]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show q Table for the reenforcement learning\n",
    "qTable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FrozenLake\n",
    "![screenshot of Environment](Screenshot_FrozenLake.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "epochs = 10001\n",
    "discount_factor = 0.1\n",
    "alpha = 0.5      #learning_rate\n",
    "epsilon= 0.3     #exploration_rate\n",
    "\n",
    "# Start Enviroment\n",
    "env = gym.make(\"FrozenLake-v0\").env\n",
    "env.reset()\n",
    "\n",
    "qTable = np.zeros([env.observation_space.n, env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Episode: 100\n",
      "Episode: 200\n",
      "Episode: 300\n",
      "Episode: 400\n",
      "Episode: 500\n",
      "Episode: 600\n",
      "Episode: 700\n",
      "Episode: 800\n",
      "Episode: 900\n",
      "Episode: 1000\n",
      "Episode: 1100\n",
      "Episode: 1200\n",
      "Episode: 1300\n",
      "Episode: 1400\n",
      "Episode: 1500\n",
      "Episode: 1600\n",
      "Episode: 1700\n",
      "Episode: 1800\n",
      "Episode: 1900\n",
      "Episode: 2000\n",
      "Episode: 2100\n",
      "Episode: 2200\n",
      "Episode: 2300\n",
      "Episode: 2400\n",
      "Episode: 2500\n",
      "Episode: 2600\n",
      "Episode: 2700\n",
      "Episode: 2800\n",
      "Episode: 2900\n",
      "Episode: 3000\n",
      "Episode: 3100\n",
      "Episode: 3200\n",
      "Episode: 3300\n",
      "Episode: 3400\n",
      "Episode: 3500\n",
      "Episode: 3600\n",
      "Episode: 3700\n",
      "Episode: 3800\n",
      "Episode: 3900\n",
      "Episode: 4000\n",
      "Episode: 4100\n",
      "Episode: 4200\n",
      "Episode: 4300\n",
      "Episode: 4400\n",
      "Episode: 4500\n",
      "Episode: 4600\n",
      "Episode: 4700\n",
      "Episode: 4800\n",
      "Episode: 4900\n",
      "Episode: 5000\n",
      "Episode: 5100\n",
      "Episode: 5200\n",
      "Episode: 5300\n",
      "Episode: 5400\n",
      "Episode: 5500\n",
      "Episode: 5600\n",
      "Episode: 5700\n",
      "Episode: 5800\n",
      "Episode: 5900\n",
      "Episode: 6000\n",
      "Episode: 6100\n",
      "Episode: 6200\n",
      "Episode: 6300\n",
      "Episode: 6400\n",
      "Episode: 6500\n",
      "Episode: 6600\n",
      "Episode: 6700\n",
      "Episode: 6800\n",
      "Episode: 6900\n",
      "Episode: 7000\n",
      "Episode: 7100\n",
      "Episode: 7200\n",
      "Episode: 7300\n",
      "Episode: 7400\n",
      "Episode: 7500\n",
      "Episode: 7600\n",
      "Episode: 7700\n",
      "Episode: 7800\n",
      "Episode: 7900\n",
      "Episode: 8000\n",
      "Episode: 8100\n",
      "Episode: 8200\n",
      "Episode: 8300\n",
      "Episode: 8400\n",
      "Episode: 8500\n",
      "Episode: 8600\n",
      "Episode: 8700\n",
      "Episode: 8800\n",
      "Episode: 8900\n",
      "Episode: 9000\n",
      "Episode: 9100\n",
      "Episode: 9200\n",
      "Episode: 9300\n",
      "Episode: 9400\n",
      "Episode: 9500\n",
      "Episode: 9600\n",
      "Episode: 9700\n",
      "Episode: 9800\n",
      "Episode: 9900\n",
      "Episode: 10000\n"
     ]
    }
   ],
   "source": [
    "# learning process\n",
    "frames = []     # save frames for video of learning process\n",
    "for i in range(epochs):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    reward, penalty = 0,0\n",
    "    \n",
    "    while not done:\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(qTable[state])\n",
    "        next_state, reward, done, _ = env.step(action) \n",
    "        old_q = qTable[state,action]\n",
    "        next_max = np.max(qTable[next_state])\n",
    "        if next_state in [5,7,11,12]:\n",
    "            penalty += 1\n",
    "            reward -=10\n",
    "        elif next_state==15:\n",
    "            reward +=20\n",
    "        else:\n",
    "            reward-=1\n",
    "        new_q = (1-alpha)*old_q + alpha*(reward + discount_factor*next_max)\n",
    "        qTable[state,action]=new_q\n",
    "\n",
    "            \n",
    "        state = next_state\n",
    "        \n",
    "        frames.append({\n",
    "            'frame': env.render(mode='ansi'),\n",
    "            'state': state,\n",
    "            'action': action,\n",
    "            'reward': reward\n",
    "            }      \n",
    "        )\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Episode: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "\n",
      "Timestep: 100\n",
      "State: 4\n",
      "Action: 2\n",
      "Reward: -1.0\n"
     ]
    }
   ],
   "source": [
    "# shows video of learning process\n",
    "print_frames(frames[99900:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 1000 episodes:\n",
      "Average timesteps per episode: 17.077\n",
      "Average penalties per episode: 17.077\n",
      "Average reward per episode: -10.878\n"
     ]
    }
   ],
   "source": [
    "total_episodes, total_penalties, total_rewards = 0, 0,0\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "for _ in range(epochs):\n",
    "    state = env.reset()\n",
    "    episodes, penalties, reward = 0, 0, 0\n",
    "    done = False\n",
    "    will_done=False\n",
    "    \n",
    "    while not done:\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(qTable[state])        \n",
    "        \n",
    "        state, reward, will_done, info = env.step(action)\n",
    "\n",
    "        if next_state in [5,7,11,12]:\n",
    "            penalties += 1\n",
    "            reward -=10\n",
    "        if next_state==15:\n",
    "            reward +=20 \n",
    "        else:\n",
    "            reward -=1\n",
    "        episodes +=1\n",
    "        done = will_done\n",
    "\n",
    "\n",
    "    total_penalties += penalties\n",
    "    total_episodes += episodes\n",
    "    total_rewards += reward\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "print(f\"Results after {epochs} episodes:\")\n",
    "print(f\"Average timesteps per episode: {total_episodes / epochs}\")\n",
    "print(f\"Average penalties per episode: {total_penalties / epochs}\")\n",
    "print(f\"Average reward per episode: {total_rewards / epochs}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MountainCar with non-random Start-State\n",
    "![screenshot of environment](Screenshot_MountainCart.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.46237893,  0.        ])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "min_epsilon = 0.1\n",
    "min_alpha = 0.1\n",
    "epochs = 10000\n",
    "lr = 1.0\n",
    "\n",
    "# Start Environment\n",
    "env = gym.make(\"MountainCar-v0\").env\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frames):\n",
    "    plt.plot(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update alpha, uses logaritmic decrease\n",
    "def get_alpha(epoch):\n",
    "    return max(min_alpha, min(0., 1.0 - math.log10((epoch+1)/25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update epsilon, uses logaritmic decrease\n",
    "def get_epsilon(epoch):\n",
    "    return max(min_epsilon, min(0., 1.0 - math.log10((epoch+1)/25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate state depending on x and v\n",
    "# uses 10 buckets for x and v  --> 100 different states\n",
    "def calculate_state(observation):\n",
    "    x,v = observation\n",
    "    \n",
    "    scale_x = (x + abs(env.observation_space.low[0])) / (env.observation_space.high[0]-env.observation_space.low[0])\n",
    "    x_state = min(9,max(0,int(round(9*scale_x))))\n",
    "    \n",
    "    scale_v = (v + abs(env.observation_space.low[1])) / (env.observation_space.high[1]-env.observation_space.low[1])\n",
    "    v_state = min(9,max(0, int(round(9*scale_v))))\n",
    "    \n",
    "    \n",
    "    return tuple([x_state,v_state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning Process\n",
    "frames = []\n",
    "qTable = np.zeros((10,10)+(3,))\n",
    "for i in range(epochs):\n",
    "    state = calculate_state(env.reset())\n",
    "    done = False\n",
    "    alpha = get_alpha(i)\n",
    "    epsilon = get_epsilon(i)\n",
    "    state=(8,8)       # fixed start space\n",
    "    for t in range(500):\n",
    "        env.render()       # uncomment to render the learning process, is very slow\n",
    "        if random.uniform (0,1) <= epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(qTable[state])\n",
    "        observation, reward, done , _ = env.step( action ) \n",
    "        next_state = calculate_state(observation)\n",
    "        \n",
    "        old_q = qTable[state][action]\n",
    "        next_max = np.max(qTable[next_state])\n",
    "        qTable[state][action] = (1.-alpha)*old_q + alpha*(reward + lr*next_max)\n",
    "        state = next_state\n",
    "        \n",
    "        if observation[0] >= 0.5:\n",
    "            print(\"reached\")\n",
    "        \n",
    "        if done:\n",
    "            frames.append(t)\n",
    "            print(f\"Episode finished after {t} timesteps.\")\n",
    "            break\n",
    "#plot(frames)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
